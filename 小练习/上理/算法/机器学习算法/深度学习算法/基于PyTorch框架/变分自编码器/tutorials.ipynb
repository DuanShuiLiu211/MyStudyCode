{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd8c8a75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T07:10:53.507526Z",
     "start_time": "2023-12-03T07:10:53.503757Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "891f9f69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T10:20:35.293960Z",
     "start_time": "2023-11-26T10:20:34.804258Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e1d594",
   "metadata": {},
   "source": [
    "## from AE to VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77add427",
   "metadata": {},
   "source": [
    "- references\n",
    "    - https://arxiv.org/pdf/1312.6114.pdf\n",
    "- AE 一般都是降维的，AE 一般用来压缩重构，VAE 则是用来做 generative，做图像生成；\n",
    "    - latent/smaller/compressed representation；\n",
    "    - 关于 latent variables（$z$）建模：latent variable models\n",
    "        - latent variable：hidden & 不可直接被观察到的变量（variables）；\n",
    "            - 比如对健康/智商等的评估，通过一组可观测的指标来infer；\n",
    "        - LDM：Latent Diffusion Model\n",
    "    - AE 关心的是 z（latent vectors/variables），前半部分（encoder），后半部分（decoder）只是用来监督保证学到一个很好的 encoder；\n",
    "        - VAE 关心的则是后半部分 generating 的过程；\n",
    "- 总结下来\n",
    "    - input: $x$, hidden: $\\mu, \\sigma$, output: $\\tilde x$\n",
    "        - $x$：data，可观测的；latent variable models 假设的是，latent space 中的 $z$ 导致了 $x$\n",
    "        - 概率图的角度就是 $z\\rightarrow x$（generative models 的generation process）\n",
    "    - Encoder: $q_\\phi(z|x), x\\rightarrow z$\n",
    "    - latent distribution：$z=\\mu+\\sigma\\odot \\epsilon$\n",
    "    - Decoder: $p_\\theta(x|z), z\\rightarrow \\tilde x$\n",
    "- references\n",
    "    - https://kvfrans.com/variational-autoencoders-explained/\n",
    "    - https://github.com/pytorch/examples/blob/main/vae/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13bddb3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T14:10:39.267691Z",
     "start_time": "2023-11-15T14:10:39.258057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://kvfrans.com/content/images/2016/08/autoenc.jpg\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://kvfrans.com/content/images/2016/08/autoenc.jpg\", width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b71474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T14:10:58.800735Z",
     "start_time": "2023-11-15T14:10:58.791244Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://kvfrans.com/content/images/2016/08/vae.jpg\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://kvfrans.com/content/images/2016/08/vae.jpg\", width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5442acd1",
   "metadata": {},
   "source": [
    "### 网络结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f221c2",
   "metadata": {},
   "source": [
    "- Encoder & Decoder\n",
    "    - Encoder：$q(z|x)$（神经网络参数为 $\\phi$） => $q_\\phi(z|x)$\n",
    "        - inference network，推断 latent variables $z$\n",
    "    - Decoder: $p(x|z)$（神经网络参数为 $\\theta$）=> $p_\\theta(x|z)$\n",
    "        - generate network\n",
    "- latent space\n",
    "    - 编码器的输出，是两个向量，一个是均值向量 $\\mu$，一个是标准差向量 $\\sigma$，它们长度相同，它们一起定义了输入数据在 latent space 中的 representation；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9557a4a",
   "metadata": {},
   "source": [
    "## loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5565d4",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal L(\\theta, \\phi;\\mathbf x, \\mathbf z)=\\underbrace{\\mathbb E_{q_\\phi(z|x)}\\left[\\log p_\\theta(x|z)\\right]}_{\\text{reconstruction loss}}-\\underbrace{D_{KL}\\left(q_\\phi(z|x)\\|p(z)\\right)}_{\\text{stay close to Normal(0,1)}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c101e062",
   "metadata": {},
   "source": [
    "### variational inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e17497f",
   "metadata": {},
   "source": [
    "- 我们想要计算 $z$ 的后验概率\n",
    "\n",
    "    $$\n",
    "    p_\\theta(z|x)=\\frac{p_\\theta(x|z)p_\\theta(z)}{p_\\theta(x)}=\\frac{p_\\theta(x|z)p_\\theta(z)}{\\int p_\\theta(x, z)dz}\n",
    "    $$\n",
    "    - 比较难计算的是分母的 $p_\\theta(x)$（marginal likelihood or evidence），有如下的两种计算思路：\n",
    "        - Monte Carlo sampling\n",
    "        - variational inference\n",
    "\n",
    "- 现如果要计算 **后验 $p_\\theta(z|x)$，我们引入 $q_\\phi(z)$**（也是一个概率分布 $\\sum_zq_\\phi(z)=1$） 来逼近，\n",
    "    \n",
    "$$\n",
    "\\begin{split}\n",
    "KL\\left[q_\\phi(z)\\|p_\\theta(z|x)\\right]&=-\\sum_zq_\\phi(z)\\log \\frac{p_\\theta(z|x)}{q_\\phi(z)}\\\\\n",
    "&=-\\underset{z}{\\sum} q_{\\phi}(z) \\log \\bigg( \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z)} \\cdot \\frac{1}{p_{\\theta}(x)} \\bigg) \\\\\n",
    "&= -\\underset{z}{\\sum} q_{\\phi}(z) \\bigg( \\log\\frac{p_{\\theta}(x,z)}{q_{\\phi}(z)} - \\log p_{\\theta}(x) \\bigg) \\\\\n",
    "&= -\\underset{z}{\\sum} q_{\\phi}(z) \\log \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z)} + \\underset{z}{\\sum} q_{\\phi}(z) \\log p_{\\theta}(x)\\\\\n",
    "&==\n",
    "-\\underset{z}{\\sum} q_{\\phi}(z) \\log \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z)} + \\log p_{\\theta}(x)\n",
    "\\end{split}\n",
    "$$\n",
    "    \n",
    "$$\n",
    "\\log p_{\\theta}(x) = \\underbrace{KL[q_{\\phi}(z) \\lVert p_{\\theta}(z \\lvert x)]}_{\\text{kl div}} + \\underbrace{\\underset{z}{\\sum} q_{\\phi}(z) \\log \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z)}}_{\\text{variational lower bound /ELBO}}\\\\\n",
    "\\underbrace{\\underset{z}{\\sum} q_{\\phi}(z) \\log \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z)}}_{\\text{variational lower bound /ELBO}}=\\log p_{\\theta}(x)-\\underbrace{KL[q_{\\phi}(z) \\lVert p_{\\theta}(z \\lvert x)]}_{\\text{kl div}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133d7f92",
   "metadata": {},
   "source": [
    "### ELBO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108d0f6c",
   "metadata": {},
   "source": [
    "- Evidence ($p(x)$) Lower BOund\n",
    "\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    \\mathcal{L} &= \\underset{z}{\\sum} q_{\\phi}(z) \\log \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z)} \\\\\n",
    "    &= \\mathbb{E}_{q_{\\phi}(z)} \\log \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z)}\n",
    "    \\end{align}\n",
    "    $$\n",
    "    \n",
    "    - 因为 KL div 非负，因此有 $\\log p_\\theta(x)\\geq \\mathcal L$，$\\mathcal L$ 是 marginal log likelihood 的 lower bound \n",
    "    - variational inference 聚焦在如何提升 ELBO 而不是最大似然；\n",
    "        - 最大化 ELBO 的过程，也是最大化 $\\log p_{\\theta}(x)$ （maximizing the evidence $p(x)$） 和最小化 $\\underbrace{KL[q_{\\phi}(z) \\lVert p_{\\theta}(z \\lvert x)]}_{\\text{kl div}}$ 的过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c94a2f85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T10:49:10.329287Z",
     "start_time": "2023-11-19T10:49:10.320036Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://jejjohnson.github.io/research_notebook/_images/elbo_inequality.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(\n",
    "    url=\"https://jejjohnson.github.io/research_notebook/_images/elbo_inequality.png\",\n",
    "    width=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe9803",
   "metadata": {},
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e1fc31",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{L} &= \\underset{z}{\\sum} q_{\\phi}(z) \\log \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z)} \\\\\n",
    "&= \\mathbb{E}_{q_{\\phi}(z)} \\log \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z)} \\\\\n",
    "&= \\mathbb{E}_{q_{\\phi}(z)} \\log \\frac{p_{\\theta}(x \\lvert z)p_{\\theta}(z)}{q_{\\phi}(z)} \\\\\n",
    "&= \\mathbb{E}_{q_{\\phi}(z)} \\log p_{\\theta}(x \\lvert z) +  \\mathbb{E}_{q_{\\phi}(z)} \\log \\frac{p_{\\theta}(z)}{q_{\\phi}(z)} \\\\\n",
    "&= \\mathbb{E}_{q_{\\phi}(z)} \\log p_{\\theta}(x \\lvert z) - KL[q_{\\phi}(z) \\lVert p_{\\theta}(z)]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- 因为我们选择 $q_\\phi(z)$ 就是为了逼近后验 $p_\\theta(z|x)$, 我们选择让 $z$ conditional on $x$，也即是$q_\\phi(z)=q_\\phi(z|x)$，因此 \n",
    "\n",
    "    $$\n",
    "    \\mathcal L=\\underbrace{\\mathbb{E}_{q_{\\phi}(z|x)} \\log p_{\\theta}(x \\lvert z)}_{\\text{reconstruction loss}}\\underbrace{- KL[q_{\\phi}(z|x) \\lVert p_{\\theta}(z)]}_{\\text{regularization}}\n",
    "    $$\n",
    "    - $p_\\theta(z)=\\mathcal N(0,I)$（diagonal unit Gaussian），先验的假设；\n",
    "\n",
    "- 该公式便是著名的 VAE 的最大化的目标（最大化 elbo）；\n",
    "    - 注意是最大化，最大化的右边不是 loss，对其取负号，表示的才是要最小化的目标；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c56369a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T09:06:48.130975Z",
     "start_time": "2023-11-26T09:06:48.114592Z"
    }
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim=784, h_dim=400, z_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, h_dim)\n",
    "\n",
    "        # mu\n",
    "        self.fc21 = nn.Linear(h_dim, z_dim)\n",
    "        # logvar\n",
    "        self.fc22 = nn.Linear(h_dim, z_dim)\n",
    "\n",
    "        self.fc3 = nn.Linear(z_dim, h_dim)\n",
    "        self.fc4 = nn.Linear(h_dim, input_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # torch.normal() 算子是不可微分\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        return z\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319894bb",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\log\\sigma^2}2=\\log \\sigma\\\\\n",
    "\\exp\\left(\\frac{\\log\\sigma^2}2\\right)=\\exp(\\log \\sigma)=\\sigma\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8449d3e",
   "metadata": {},
   "source": [
    "## training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4c21a5",
   "metadata": {},
   "source": [
    "### sampling: reparameterization trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45ef33ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:32:51.898719Z",
     "start_time": "2023-11-15T15:32:51.887972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/v2/resize:fit:4800/format:webp/1*I9532-09gKnRR43acCFedQ.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(\n",
    "    url=\"https://miro.medium.com/v2/resize:fit:4800/format:webp/1*I9532-09gKnRR43acCFedQ.png\",\n",
    "    width=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d1a23e",
   "metadata": {},
   "source": [
    "- 重参数化技巧使得反向传播成为可能；\n",
    "    - 在VAE中，我们希望从潜在空间（latent space）中抽取样本，这个潜在空间通常是由神经网络输出的一些参数（如均值和方差）定义的正态分布。然而，直接从这种分布中抽取样本是一个随机过程，这使得无法直接对其进行反向传播，因为梯度无法穿过随机节点。\n",
    "- 重参数化技巧，它的基本思想是将随机抽样过程重写为一个可微分的操作，具体操作如下：\n",
    "    - 分离随机性和网络参数，$q_\\phi(z|x)$ 预测 $\\mu,\\sigma$, 我们不再是从该参数化的分布中直接进行采样，而是从一个标准正态分布 $\\mathcal N(0,1)$ 中抽取一个随机噪声，$\\epsilon$\n",
    "    - 重参数化转换，基于上一步，我们可以计算latent variable $z=\\mu+\\sigma\\odot \\epsilon=g_{\\mu,\\sigma}(\\epsilon)$ （element-wise product）\n",
    "        - 这里的关键是噪声 $\\epsilon$ 是随机的，但是一旦抽取，它就是一个固定的值，使得整个表达式变得可微分。\n",
    "        - $z=\\mu+\\sigma\\odot\\epsilon$ 而不是 $z\\sim q_\\phi(z|x)$，直接取值，而不是采样；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77a4c59d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:35:55.969675Z",
     "start_time": "2023-11-15T15:35:55.959474Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.stack.imgur.com/TzX3I.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://i.stack.imgur.com/TzX3I.png\", width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3765c460",
   "metadata": {},
   "source": [
    "### training loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e5d8e0",
   "metadata": {},
   "source": [
    "```\n",
    "重建损失交叉熵\n",
    "reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "```\n",
    "$$\n",
    "H(x, \\hat{x}) = - \\left( x \\log(\\hat{x}) + (1 - x) \\log(1 - \\hat{x}) \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "```\n",
    "隐空间损失KL散度\n",
    "kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "```\n",
    "$$\n",
    "\\int q_{\\theta}(z) \\log p(z) dz = \\int \\mathcal{N}(z; \\mu, \\sigma^2) \\log \\mathcal{N}(z; 0, I) dz\n",
    "\n",
    "= -\\frac{J}{2} \\log(2\\pi) - \\frac{1}{2} \\sum_{j=1}^{J} (\\mu_j^2 + \\sigma_j^2)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\int q_{\\theta}(z) \\log p(z) \\, dz = \\int \\mathcal{N}(z; \\mu, \\sigma^2) \\log \\mathcal{N}(z; 0, \\mathbf{I}) \\, dz\n",
    "= -\\frac{J}{2} \\log(2\\pi) - \\frac{1}{2} \\sum_{j=1}^{J} (1 + \\log \\sigma_j^2)\n",
    "$$\n",
    "\n",
    "$$\n",
    "-D_{KL}(q_{\\theta}(z) || p(z)) = \\int q_{\\theta}(z) (\\log p(z) - \\log q_{\\theta}(z)) \\, dz\n",
    "= \\frac{1}{2} \\sum_{j=1}^{J} (1 + \\log(\\sigma_j^2) - \\mu_j^2 - \\sigma_j^2)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f400a1b8",
   "metadata": {},
   "source": [
    "### inference/generating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf256997",
   "metadata": {},
   "source": [
    "```\n",
    "从标准正态分布中进行采样\n",
    "z = torch.randn(batch_size, z_dim).to(device)\n",
    "out = model.decode(z).view(-1, 1, 28, 28)\n",
    "```\n",
    "\n",
    "- 编码空间（潜在空间）通常是连续的，可以从潜在空间中随机采样并通过解码器生成新的图像。\n",
    "    - samaple from a distribution\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a60e48",
   "metadata": {},
   "source": [
    "## coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f1e3ac7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T09:03:10.210186Z",
     "start_time": "2023-11-26T09:03:10.196980Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basic configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ac24779",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T11:50:57.802376Z",
     "start_time": "2023-11-26T11:50:57.796000Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "image_size = 784  # 28*28\n",
    "h_dim = 400\n",
    "z_dim = 20\n",
    "num_epochs = 20\n",
    "batch_size = 128\n",
    "learning_rate = 3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b705b118",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T09:29:43.684303Z",
     "start_time": "2023-11-26T09:29:43.598493Z"
    }
   },
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765afaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T09:06:34.393504Z",
     "start_time": "2023-11-26T09:06:34.282304Z"
    }
   },
   "outputs": [],
   "source": [
    "# FashionMNIST dataset\n",
    "dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "536fee3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T11:53:31.098907Z",
     "start_time": "2023-11-26T11:53:31.089076Z"
    }
   },
   "outputs": [],
   "source": [
    "model = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5361b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T11:55:06.154014Z",
     "start_time": "2023-11-26T11:53:33.064754Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # training\n",
    "    for i, (x, _) in enumerate(data_loader):\n",
    "\n",
    "        # Forward pass\n",
    "        x = x.to(device).view(-1, image_size)\n",
    "        x_reconst, mu, log_var = model(x)\n",
    "\n",
    "        # Compute reconstruction loss and kl divergence\n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "        kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "\n",
    "        # Backprop and optimize\n",
    "        loss = reconst_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 200 == 0:\n",
    "            print(\n",
    "                \"Epoch [{}/{}], Step [{}/{}], total Loss: {:.4f} = Reconst Loss: {:.4f} + KL Div: {:.4f}\".format(\n",
    "                    epoch + 1,\n",
    "                    num_epochs,\n",
    "                    i + 1,\n",
    "                    len(data_loader),\n",
    "                    loss.item(),\n",
    "                    reconst_loss.item(),\n",
    "                    kl_div.item(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # sampling/generating\n",
    "    result_dir = \"results\"\n",
    "    if not os.path.exists(result_dir):\n",
    "        os.makedirs(result_dir)\n",
    "    with torch.no_grad():\n",
    "        # 从正态分布中进行采样\n",
    "        z = torch.normal(mu.mean(), log_var.mean().abs(), size=(batch_size, z_dim)).to(\n",
    "            device\n",
    "        )\n",
    "        out = model.decode(z).view(-1, 1, 28, 28)\n",
    "        save_image(out, os.path.join(result_dir, \"sampled_{}.png\".format(epoch + 1)))\n",
    "\n",
    "        # 原始结果对比重构结果\n",
    "        out, _, _ = model(x)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n",
    "        save_image(\n",
    "            x_concat, os.path.join(result_dir, \"reconst_{}.png\".format(epoch + 1))\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
