{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from math import exp\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. ***用于二分类任务或重建任务，loss function bce***\n",
    "***F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)***\n",
    "- weight (Tensor, optional): a manual rescaling weight given to the loss of each batch element.\n",
    "- This is used for measuring the error of a reconstruction in for example an auto-encoder.\n",
    "\n",
    "***The unreduced (i.e. with `reduction` set to ``'none'``) loss can be described as***\n",
    "\n",
    "$$\n",
    "\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
    "l_n = - w_n \\left[ y_n \\cdot \\log x_n + (1 - y_n) \\cdot \\log (1 - x_n) \\right],\n",
    "$$\n",
    "\n",
    "- `N` is the batch size. \n",
    "- targets `y` should be numbers between 0 and 1.\n",
    "\n",
    "***If `reduction` is not ``'none'`` (default ``'mean'``), then***\n",
    "\n",
    "$$\n",
    "\\ell(x, y) = \\begin{cases}\n",
    "\\operatorname{mean}(L), \\quad & \\text{if reduction} = \\text{`mean';}\\\\\n",
    "\\operatorname{sum}(L), \\quad & \\text{if reduction} = \\text{`sum'.}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bce = nn.BCELoss()\n",
    "\n",
    "def binary_cross_entorpy(inputs, targets):\n",
    "    inputs = inputs.numpy()\n",
    "    inputs = inputs.reshape((inputs.shape[0]*inputs.shape[1], inputs.shape[-2]*inputs.shape[-1]))\n",
    "    targets = targets.numpy()\n",
    "    targets = targets.reshape((targets.shape[0]*targets.shape[1], targets.shape[-2]*targets.shape[-1]))\n",
    "    outputs = 0.\n",
    "    weight = 1.\n",
    "    for i in range(targets.shape[0]):\n",
    "        temp = 0\n",
    "        for j in range(targets.shape[1]):\n",
    "            temp += -1. * weight * (targets[i, j]*np.log(inputs[i, j]) + (1-targets[i, j])*np.log(1-inputs[i, j]))\n",
    "        outputs += (temp / targets.shape[1])\n",
    "        \n",
    "    return outputs / targets.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.4346, 0.9757],\n",
      "          [0.5365, 0.6144]],\n",
      "\n",
      "         [[0.2446, 0.2691],\n",
      "          [0.7291, 0.4737]]]])\n",
      "tensor([[[[0.5867, 0.4917],\n",
      "          [0.5620, 0.5491]],\n",
      "\n",
      "         [[0.4133, 0.5083],\n",
      "          [0.4380, 0.4509]]]])\n",
      "bce 0.892566\n",
      "binary_cross_entorpy 0.892566\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.rand((1, 2, 2, 2))\n",
    "outputs = torch.tensor([[[[0, 1.], [1., 0]], [[0, 1.], [1., 0]]]])\n",
    "# outputs = torch.nn.Softmax(dim=1)(torch.rand(1, 2, 2, 2))\n",
    "\n",
    "print(inputs,\n",
    "      outputs,\n",
    "      f'bce {bce(inputs, outputs):6f}',\n",
    "      f'binary_cross_entorpy {binary_cross_entorpy(inputs, outputs):6f}',\n",
    "      sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. ***用于多分类任务，loss function ce***\n",
    "***F.cross_entropy(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction, label_smoothing=self.label_smoothing)***\n",
    "- this case is equivalent to the combination of `~torch.nn.LogSoftmax` and `~torch.nn.NLLLoss`.\n",
    "  > $$\\text{LogSoftmax}(x_{i}) = \\log\\left(\\frac{\\exp(x_i) }{ \\sum_j \\exp(x_j)} \\right)$$\n",
    "  > $$Nll(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
    "        l_n = - w_{y_n} x_{n,y_n}, \\quad\n",
    "        w_{c} = \\text{weight}[c] \\cdot \\mathbb{1}\\{c \\not= \\text{ignore\\_index}\\}$$\n",
    "- It is useful when training a classification problem with `C` classes.\n",
    "- If provided, the optional argument `weight` should be a 1D `Tensor` assigning weight to each of the classes, This is\n",
    "particularly useful when you have an unbalanced training set.\n",
    "\n",
    "***The `input` is expected to contain raw, unnormalized scores for each class.***\n",
    "- `input` has to be a Tensor of size `(C)` for unbatched input, `(N, C)` or `(N, C, d_1, d_2, ..., d_K)` with $K\\geq 1$ for the `K`-dimensional case.\n",
    "  > $$\\begin{aligned}\n",
    "      C ={} & \\text{number of classes} \\\\\n",
    "      N ={} & \\text{batch size} \\\\\n",
    "      \\end{aligned}$$\n",
    "\n",
    "***The `target` that this criterion expects should contain either***\n",
    "- Class indices in the range `[0, C)` where `C` is the number of classes, not one-hot, dtype is long.\n",
    "- if `ignore_index` is specified, loss also accepts this class index (this index may not necessarily be in the class range).\n",
    "- If containing class probabilities, same shape as the input and each value should be between `[0, 1]`, dtype is float.\n",
    "- The unreduced (i.e. with `reduction` set to ``'none'``) loss for this case can be described as\n",
    "\n",
    "$$\n",
    "\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
    "l_n = - w_{y_n} \\log \\frac{\\exp(x_{n,y_n})}{\\sum_{c=1}^C \\exp(x_{n,c})}\n",
    "\\cdot \\mathbb{1}\\{y_n \\not= \\text{ignore\\_index}\\}\n",
    "$$\n",
    "\n",
    "`x` is the input, `y` is the target, `w` is the weight,\n",
    "`C` is the number of classes, and `N` spans the minibatch dimension as well as `d_1, ..., d_k` for the `K`-dimensional case.\n",
    "\n",
    "- The performance of this criterion is generally better when `target` contains class\n",
    "  indices, as this allows for optimized computation. Consider providing `target` as\n",
    "  class probabilities only when a single class label per minibatch item is too restrictive.\n",
    "\n",
    "***The `output` If reduction is 'none', same shape as the target. Otherwise, scalar.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ce = nn.CrossEntropyLoss()\n",
    "ls = nn.LogSoftmax(dim=1)\n",
    "nll = nn.NLLLoss()\n",
    "\n",
    "\n",
    "def cross_entorpy(inputs, targets):\n",
    "    inputs = inputs.numpy()\n",
    "    targets = targets.numpy()\n",
    "    outputs = 0.\n",
    "    weight = 1.\n",
    "    if targets.dtype == np.int64:\n",
    "        assert len(inputs.shape) == 4 and len(targets.shape) == 3\n",
    "        for k in range(targets.shape[0]):\n",
    "            temp = 0.\n",
    "            for i in range(targets.shape[-2]):\n",
    "                for j in range(targets.shape[-1]):\n",
    "                    temp += -1. * weight * (np.log(np.exp(inputs[k, :, i, j][..., int(targets[k, i, j].item())]) /\n",
    "                            np.sum(np.exp(inputs[k, :, i, j]))))\n",
    "            outputs += temp\n",
    "    elif targets.dtype == np.float32:\n",
    "        assert inputs.shape == targets.shape\n",
    "        for k in range(targets.shape[0]):\n",
    "            temp = 0.\n",
    "            for i in range(targets.shape[-2]):\n",
    "                for j in range(targets.shape[-1]):\n",
    "                    temp += -1. * weight * np.sum(np.log(np.exp(inputs[k, :, i, j]) / np.sum(np.exp(inputs[k, :, i, j]))) * targets[k, :, i, j])\n",
    "            outputs += temp\n",
    "    else:\n",
    "        print(f'标签的数据类型应该是 int64 或者 float32 而不是 {targets.dtype}')\n",
    "        sys.exit()\n",
    "\n",
    "    return (outputs / (targets.shape[0] * targets.shape[-2] * targets.shape[-1])).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce 0.725609\n",
      "logsoftmax+nll 0.725609\n",
      "cross_entorpy 0.725609\n"
     ]
    }
   ],
   "source": [
    "# 交叉熵的计算模式 - 标签中的元素是类的索引值, [0, C-1] -> int64\n",
    "inputs = torch.rand(2, 2, 5, 5)\n",
    "targets = torch.rand(2, 5, 5).random_(2).long()\n",
    "\n",
    "# # 交叉熵的计算模式 - 标签中的元素是类的概率值, [0, 1] -> float32\n",
    "# inputs = torch.rand(2, 2, 5, 5)\n",
    "# targets = torch.nn.Softmax(dim=1)(torch.rand(2, 2, 5, 5))\n",
    "\n",
    "outputs = ce(inputs, targets)\n",
    "print(f'ce {outputs:6f}')\n",
    "\n",
    "if targets.dtype == torch.int64:\n",
    "    outputs = nll(ls(inputs), targets)\n",
    "    print(f'logsoftmax+nll {outputs:6f}')\n",
    "\n",
    "outputs = cross_entorpy(inputs, targets)\n",
    "print(f'cross_entorpy {outputs:6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ***用于重建任务，loss function ssim***\n",
    "- 结构相似性指数（structural similarity index，SSIM）用于度量两幅图像间的结构相似性。和被广泛采用的L2 loss不同，SSIM和人类的视觉系统（HVS）类似，对局部结构变化的感知敏感"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算一维的高斯分布向量\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([\n",
    "        exp(-(x - window_size // 2)**2 / float(2 * sigma**2))\n",
    "        for x in range(window_size)\n",
    "    ])\n",
    "    return gauss / gauss.sum()\n",
    "\n",
    "\n",
    "# 创建高斯核，通过两个一维高斯分布向量进行矩阵乘法得到\n",
    "# 可以设定channel参数拓展为3通道\n",
    "def create_window(window_size, channel=1):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(\n",
    "        _1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = _2D_window.expand(channel, 1, window_size,\n",
    "                               window_size).contiguous()\n",
    "    return window\n",
    "\n",
    "\n",
    "# 计算SSIM\n",
    "# 直接使用SSIM的公式，但是在计算均值时，不是直接求像素平均值，而是采用归一化的高斯核卷积来代替。\n",
    "# 在计算方差和协方差时用到了公式Var(X)=E[X^2]-E[X]^2, cov(X,Y)=E[XY]-E[X]E[Y].\n",
    "# 正如前面提到的，上面求期望的操作采用高斯核卷积代替。\n",
    "def ssim(img1,\n",
    "         img2,\n",
    "         window_size=11,\n",
    "         window=None,\n",
    "         size_average=True,\n",
    "         full=False,\n",
    "         val_range=None):\n",
    "    # Value range can be different from 255. Other common ranges are 1 (sigmoid) and 2 (tanh).\n",
    "    if val_range is None:\n",
    "        if torch.max(img1) > 128:\n",
    "            max_val = 255\n",
    "        else:\n",
    "            max_val = 1\n",
    "\n",
    "        if torch.min(img1) < -0.5:\n",
    "            min_val = -1\n",
    "        else:\n",
    "            min_val = 0\n",
    "        L = max_val - min_val\n",
    "    else:\n",
    "        L = val_range\n",
    "\n",
    "    padd = 0\n",
    "    (_, channel, height, width) = img1.size()\n",
    "    if window is None:\n",
    "        real_size = min(window_size, height, width)\n",
    "        window = create_window(real_size, channel=channel).to(img1.device)\n",
    "\n",
    "    mu1 = F.conv2d(img1, window, padding=padd, groups=channel)\n",
    "    mu2 = F.conv2d(img2, window, padding=padd, groups=channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=padd,\n",
    "                         groups=channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=padd,\n",
    "                         groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1 * img2, window, padding=padd,\n",
    "                       groups=channel) - mu1_mu2\n",
    "\n",
    "    C1 = (0.01 * L)**2\n",
    "    C2 = (0.03 * L)**2\n",
    "\n",
    "    v1 = 2.0 * sigma12 + C2\n",
    "    v2 = sigma1_sq + sigma2_sq + C2\n",
    "    cs = torch.mean(v1 / v2)  # contrast sensitivity\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * v1) / ((mu1_sq + mu2_sq + C1) * v2)\n",
    "\n",
    "    if size_average:\n",
    "        ret = ssim_map.mean()\n",
    "    else:\n",
    "        ret = ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "    if full:\n",
    "        return ret, cs\n",
    "    return ret\n",
    "\n",
    "\n",
    "# Classes to re-use window\n",
    "class SSIM(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, window_size=11, size_average=True, val_range=None):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.val_range = val_range\n",
    "\n",
    "        # Assume 1 channel for SSIM\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.dtype == img1.dtype:\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size,\n",
    "                                   channel).to(img1.device).type(img1.dtype)\n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "        return ssim(img1,\n",
    "                    img2,\n",
    "                    window=window,\n",
    "                    window_size=self.window_size,\n",
    "                    size_average=self.size_average)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7567524e79b96d316162151a38259d28be4bc298929f85b9103bf7fbca02c0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
