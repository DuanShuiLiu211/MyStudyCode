{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plot\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 组织数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_images(folder_path):\n",
    "    image_dict = {}\n",
    "    for dirpath, _, filenames in os.walk(folder_path):\n",
    "        for filename in filenames:\n",
    "            if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "                folder_name = os.path.basename(os.path.dirname(file_path))\n",
    "                if folder_name not in image_dict:\n",
    "                    image_dict[folder_name] = []\n",
    "                image_dict[folder_name].append(file_path)\n",
    "    return image_dict\n",
    "\n",
    "\n",
    "def copy_images(image_dict, new_folder_path):\n",
    "    for folder_name, file_paths in image_dict.items():\n",
    "        for i, file_path in enumerate(file_paths):\n",
    "            new_file_name = f\"{folder_name}_{i+1}{os.path.splitext(file_path)[1]}\"\n",
    "            if not os.path.exists(os.path.join(new_folder_path, folder_name)):\n",
    "                os.makedirs(os.path.join(new_folder_path, folder_name))\n",
    "            new_file_path = os.path.join(new_folder_path, folder_name, new_file_name)\n",
    "            shutil.copy(file_path, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/Users/WangHao/Sites/学习/Python/TuLiProject/TrainNetPipeline/datas/character_advance/chinese/新\"\n",
    "image_dict = gather_images(image_dir)\n",
    "\n",
    "new_folder_path = \"/Users/WangHao/Sites/学习/Python/TuLiProject/TrainNetPipeline/datas/character_advance/chinese/新_1\"\n",
    "copy_images(image_dict, new_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images_total(folder_path):\n",
    "    chinese_images = []\n",
    "    nonchinese_images = []\n",
    "    for dirpath, _, filenames in os.walk(folder_path):\n",
    "        kind_name = os.path.basename(os.path.dirname(dirpath))\n",
    "        if \"nonchinese\" not in kind_name:\n",
    "            for filename in filenames:\n",
    "                if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                    file_path = os.path.join(dirpath, filename)\n",
    "                    chinese_images.append(file_path)\n",
    "        elif \"nonchinese\" in kind_name:\n",
    "            for filename in filenames:\n",
    "                if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                    file_path = os.path.join(dirpath, filename)\n",
    "                    nonchinese_images.append(file_path)\n",
    "    print(f\"chinese images total: {len(chinese_images)}\")\n",
    "    print(f\"nonchinese images total: {len(nonchinese_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_images_total(\n",
    "    \"/Users/WangHao/Sites/学习/LargeData/licence_plate_character\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images_side(folder_path):\n",
    "    images_side_dict = {}\n",
    "    for dirpath, _, filenames in os.walk(folder_path):\n",
    "        for filename in filenames:\n",
    "            if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "                image = Image.open(file_path)\n",
    "                width, height = image.size\n",
    "                images_side_dict[file_path] = [width, height]\n",
    "\n",
    "    # 根据模糊程度对图像进行排序\n",
    "    sorted_images_side = sorted(\n",
    "        images_side_dict.items(), key=lambda x: min(x[1]), reverse=True\n",
    "    )\n",
    "    return sorted_images_side\n",
    "\n",
    "\n",
    "def plot_side_histogram(sorted_images_side):\n",
    "    _, side_values = zip(*sorted_images_side)\n",
    "    plot.rcParams[\"font.family\"] = [\"Times New Roman\"]\n",
    "    plot.figure(figsize=(10, 6))\n",
    "    plot.hist(list(map(min, side_values)), bins=30, color=\"blue\", alpha=0.7)\n",
    "    plot.title(\"Image Side Distribution\")\n",
    "    plot.xlabel(\"Side\")\n",
    "    plot.ylabel(\"Frequency\")\n",
    "    plot.grid(True)\n",
    "    plot.xticks(rotation=45)\n",
    "    plot.minorticks_on()\n",
    "    plot.tick_params(axis=\"both\", which=\"both\", direction=\"in\")\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/Users/WangHao/Sites/学习/LargeData/licence_plate_character\"\n",
    "sorted_images_side = count_images_side(image_dir)\n",
    "plot_side_histogram(sorted_images_side)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模糊模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模糊程度排序\n",
    "def estimate_blur_laplacian(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    laplacian_var = cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "    return laplacian_var\n",
    "\n",
    "\n",
    "def sort_images_by_blur(folder_path):\n",
    "    blur_dict = {}\n",
    "    for dirpath, _, filenames in os.walk(folder_path):\n",
    "        for filename in filenames:\n",
    "            if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "                blur_measure = estimate_blur_laplacian(file_path)\n",
    "                blur_dict[file_path] = blur_measure\n",
    "\n",
    "    # 根据模糊程度对图像进行排序\n",
    "    sorted_images = sorted(blur_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_images\n",
    "\n",
    "\n",
    "def plot_blur_histogram(sorted_images):\n",
    "    _, blur_values = zip(*sorted_images)\n",
    "    plot.rcParams[\"font.family\"] = [\"Times New Roman\"]\n",
    "    plot.figure(figsize=(10, 6))\n",
    "    plot.hist(blur_values, bins=30, color=\"blue\", alpha=0.7)\n",
    "    plot.title(\"Image Blur Distribution\")\n",
    "    plot.xlabel(\"Blur\")\n",
    "    plot.ylabel(\"Frequency\")\n",
    "    plot.grid(True)\n",
    "    plot.xticks(rotation=45)\n",
    "    plot.minorticks_on()\n",
    "    plot.tick_params(axis=\"both\", which=\"both\", direction=\"in\")\n",
    "    plot.show()\n",
    "\n",
    "\n",
    "def plot_blur_histogram_by_folder(sorted_images):\n",
    "    folder_blur = {}\n",
    "    for file_path, blur in sorted_images:\n",
    "        # 提取直接文件夹的名称\n",
    "        folder_name = os.path.basename(os.path.dirname(file_path))\n",
    "        if folder_name not in folder_blur:\n",
    "            folder_blur[folder_name] = []\n",
    "        folder_blur[folder_name].append(blur)\n",
    "\n",
    "    # 为每个文件夹绘制亮度直方图\n",
    "    for folder_name, blur_values in folder_blur.items():\n",
    "        plot.rcParams[\"font.family\"] = [\"STFangsong\"]\n",
    "        plot.rcParams[\"axes.unicode_minus\"] = False\n",
    "        plot.figure(figsize=(10, 6))\n",
    "        plot.hist(blur_values, bins=30, color=\"blue\", alpha=0.7)\n",
    "        plot.title(f\"Image Blur Distribution in {folder_name}\")\n",
    "        plot.xlabel(\"Blur\")\n",
    "        plot.ylabel(\"Frequency\")\n",
    "        plot.grid(True)\n",
    "        plot.xticks(rotation=45)\n",
    "        plot.minorticks_on()\n",
    "        plot.tick_params(axis=\"both\", which=\"both\", direction=\"in\")\n",
    "        plot.show()\n",
    "\n",
    "\n",
    "def combine_images(sorted_images):\n",
    "    # 读取所有图像并存储它们及其尺寸\n",
    "    images = []\n",
    "    total_width = 0\n",
    "    max_height = 0\n",
    "\n",
    "    for image_path, _ in sorted_images:\n",
    "        img = np.array(Image.open(image_path))\n",
    "        images.append(img)\n",
    "        h, w, _ = img.shape\n",
    "        total_width += w\n",
    "        max_height = max(max_height, h)\n",
    "\n",
    "    # 创建一个足够大的画布\n",
    "    combined_image = np.zeros((max_height, total_width, 3), dtype=np.uint8)\n",
    "\n",
    "    # 将每张图像放置到画布上\n",
    "    current_x = 0\n",
    "    for img in images:\n",
    "        h, w, _ = img.shape\n",
    "        combined_image[:h, current_x : current_x + w, :] = img\n",
    "        current_x += w\n",
    "\n",
    "    return combined_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/Users/WangHao/Sites/学习/Python/TuLiProject/TrainNetPipeline/datas/character_advance/chinese\"\n",
    "sorted_images = sort_images_by_blur(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_blur_histogram(sorted_images)\n",
    "plot_blur_histogram_by_folder(sorted_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_image = combine_images(sorted_images)\n",
    "display(Image.fromarray(combined_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 动态模糊（模糊核的越大，模糊程度越高，设置为图像尺寸的1/5到1/3）\n",
    "def apply_motion_blur(image: np.ndarray, size=5):\n",
    "    kernel_motion_blur = np.zeros((size, size))\n",
    "    kernel_motion_blur[int((size - 1) / 2), :] = np.ones(size)\n",
    "    kernel_motion_blur = kernel_motion_blur / size\n",
    "    return cv2.filter2D(image, -1, kernel_motion_blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/Users/WangHao/Sites/学习/Python/TuLiProject/TrainNetPipeline/datas/character_advance/chinese\"\n",
    "sorted_images = sort_images_by_blur(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_pil = Image.open(sorted_images[2000][0])\n",
    "display(\n",
    "    image_data_pil.size, image_data_pil, estimate_blur_laplacian(sorted_images[2000][0])\n",
    ")\n",
    "\n",
    "image_processed = apply_motion_blur(np.array(image_data_pil), 9)\n",
    "display(Image.fromarray(image_processed))\n",
    "\n",
    "gray_image = cv2.cvtColor(image_processed, cv2.COLOR_RGB2GRAY)\n",
    "laplacian_var = cv2.Laplacian(gray_image, cv2.CV_64F).var()\n",
    "display(laplacian_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对数据集中的所有图像应用模糊模式处理\n",
    "def blur_dataset(image_dict, new_folder_path):\n",
    "    for folder_name, file_paths in image_dict.items():\n",
    "        if folder_name not in [\"chinese\", \"nonchinese\"]:\n",
    "            nums = len(file_paths)\n",
    "            for file_path in file_paths:\n",
    "                image = np.array(Image.open(file_path))\n",
    "                blur_measure = estimate_blur_laplacian(file_path)\n",
    "\n",
    "                # 计算模糊核大小的范围\n",
    "                min_side = min(image.shape[:2])\n",
    "                max_kernel_size = int(min_side / 3)\n",
    "\n",
    "                # 确保核大小为奇数\n",
    "                init_size = 3\n",
    "                size_gap = 2\n",
    "                kernel_sizes = [init_size, init_size + size_gap]\n",
    "                kernel_sizes.extend(\n",
    "                    [\n",
    "                        size\n",
    "                        for size in range(3, max_kernel_size + 1, size_gap)\n",
    "                        if size not in kernel_sizes\n",
    "                        and size <= (init_size + 3 * size_gap)\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                # 对每张图像应用不同大小的模糊核\n",
    "                for size in kernel_sizes:\n",
    "                    if nums > 5000 and size < (\n",
    "                        init_size + size_gap\n",
    "                    ):  # 数量够多的情况，跳过模糊度低的核\n",
    "                        continue\n",
    "                    if blur_measure < 10000 and size >= (\n",
    "                        init_size + size_gap\n",
    "                    ):  # 不够清晰的情况，跳过模糊度过高的核\n",
    "                        continue\n",
    "                    blurred_image = apply_motion_blur(image, size)\n",
    "                    new_file_name = f\"{os.path.splitext(os.path.basename(file_path))[0]}_blur{size}{os.path.splitext(file_path)[1]}\"\n",
    "                    new_file_path = os.path.join(\n",
    "                        new_folder_path, folder_name, new_file_name\n",
    "                    )\n",
    "\n",
    "                    if not os.path.exists(os.path.join(new_folder_path, folder_name)):\n",
    "                        os.makedirs(os.path.join(new_folder_path, folder_name))\n",
    "\n",
    "                    Image.fromarray(blurred_image).save(new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/Users/WangHao/Sites/学习/Python/TuLiProject/TrainNetPipeline/datas/character_advance/nonchinese\"\n",
    "image_dict = gather_images(image_dir)\n",
    "\n",
    "blur_dataset(image_dict, f\"{image_dir}_blur\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 曝光模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_yuv_brightness(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    yuv_image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "    brightness = np.mean(yuv_image[:, :, 0])\n",
    "    return brightness\n",
    "\n",
    "\n",
    "def sort_images_by_brightness(folder_path):\n",
    "    brightness_dict = {}\n",
    "    for dirpath, _, filenames in os.walk(folder_path):\n",
    "        for filename in filenames:\n",
    "            if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "                brightness_measure = calculate_yuv_brightness(file_path)\n",
    "                brightness_dict[file_path] = brightness_measure\n",
    "\n",
    "    sorted_images = sorted(brightness_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_images\n",
    "\n",
    "\n",
    "def plot_brightness_histogram(sorted_images):\n",
    "    _, brightness_values = zip(*sorted_images)\n",
    "    plot.rcParams[\"font.family\"] = [\"Times New Roman\"]\n",
    "    plot.rcParams[\"axes.unicode_minus\"] = False\n",
    "    plot.figure(figsize=(10, 6))\n",
    "    plot.hist(brightness_values, bins=30, color=\"blue\", alpha=0.7)\n",
    "    plot.title(\"Image Brightness Distribution\")\n",
    "    plot.xlabel(\"Brightness\")\n",
    "    plot.ylabel(\"Frequency\")\n",
    "    plot.grid(True)\n",
    "    plot.xticks(rotation=45)\n",
    "    plot.minorticks_on()\n",
    "    plot.tick_params(axis=\"both\", which=\"both\", direction=\"in\")\n",
    "    plot.show()\n",
    "\n",
    "\n",
    "def plot_brightness_histogram_by_folder(sorted_images):\n",
    "    folder_brightness = {}\n",
    "    for file_path, brightness in sorted_images:\n",
    "        # 提取直接文件夹的名称\n",
    "        folder_name = os.path.basename(os.path.dirname(file_path))\n",
    "        if folder_name not in folder_brightness:\n",
    "            folder_brightness[folder_name] = []\n",
    "        folder_brightness[folder_name].append(brightness)\n",
    "\n",
    "    # 为每个文件夹绘制亮度直方图\n",
    "    for folder_name, brightness_values in folder_brightness.items():\n",
    "        plot.rcParams[\"font.family\"] = [\"STFangsong\"]\n",
    "        plot.rcParams[\"axes.unicode_minus\"] = False\n",
    "        plot.figure(figsize=(10, 6))\n",
    "        plot.hist(brightness_values, bins=30, color=\"blue\", alpha=0.7)\n",
    "        plot.title(f\"Image Brightness Distribution in {folder_name}\")\n",
    "        plot.xlabel(\"Brightness\")\n",
    "        plot.ylabel(\"Frequency\")\n",
    "        plot.grid(True)\n",
    "        plot.xticks(rotation=45)\n",
    "        plot.minorticks_on()\n",
    "        plot.tick_params(axis=\"both\", which=\"both\", direction=\"in\")\n",
    "        plot.show()\n",
    "\n",
    "\n",
    "def combine_images(sorted_images):\n",
    "    images = []\n",
    "    total_width = 0\n",
    "    max_height = 0\n",
    "\n",
    "    for image_path, _ in sorted_images:\n",
    "        img = np.array(Image.open(image_path))\n",
    "        images.append(img)\n",
    "        h, w, _ = img.shape\n",
    "        total_width += w\n",
    "        max_height = max(max_height, h)\n",
    "\n",
    "    combined_image = np.zeros((max_height, total_width, 3), dtype=np.uint8)\n",
    "\n",
    "    current_x = 0\n",
    "    for img in images:\n",
    "        h, w, _ = img.shape\n",
    "        combined_image[:h, current_x : current_x + w, :] = img\n",
    "        current_x += w\n",
    "\n",
    "    return combined_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/Users/WangHao/Sites/学习/Python/TuLiProject/TrainNetPipeline/datas/character_advance/nonchinese\"\n",
    "sorted_images = sort_images_by_brightness(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_brightness_histogram(sorted_images)\n",
    "plot_brightness_histogram_by_folder(sorted_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_image = combine_images(sorted_images)\n",
    "Image.fromarray(combined_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 曝光（大于1.0会增加曝光，小于1.0会减少曝光，设置为0.1到3）\n",
    "def adjust_exposure(image: np.ndarray, factor=1.0):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hsv = np.array(hsv, dtype=np.float64)\n",
    "    hsv[:, :, 2] = hsv[:, :, 2] * factor\n",
    "    hsv[:, :, 2][hsv[:, :, 2] > 255] = 255\n",
    "    hsv = np.array(hsv, dtype=np.uint8)\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/Users/WangHao/Sites/学习/Python/TuLiProject/TrainNetPipeline/datas/character_advance/chinese\"\n",
    "sorted_images = sort_images_by_brightness(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_pil = Image.open(sorted_images[200][0])\n",
    "display(\n",
    "    image_data_pil.size, image_data_pil, calculate_yuv_brightness(sorted_images[200][0])\n",
    ")\n",
    "\n",
    "image_processed = adjust_exposure(np.array(image_data_pil), 0.5)\n",
    "display(Image.fromarray(image_processed))\n",
    "\n",
    "yuv_image = cv2.cvtColor(image_processed, cv2.COLOR_BGR2YUV)\n",
    "brightness = np.mean(yuv_image[:, :, 0])\n",
    "display(brightness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对数据集中的所有图像应用曝光模式处理\n",
    "def brightness_dataset(image_dict, new_folder_path):\n",
    "    for folder_name, file_paths in image_dict.items():\n",
    "        if folder_name not in [\"chinese\", \"nonchinese\"]:\n",
    "            nums = len(file_paths)\n",
    "            for file_path in file_paths:\n",
    "                image = np.array(Image.open(file_path))\n",
    "                brightness = calculate_yuv_brightness(file_path)\n",
    "\n",
    "                # 设置亮度因子的范围\n",
    "                factor_range = [0.1, 0.2, 0.5, 0.8, 1.5, 2.0, 3.0, 5.0]\n",
    "                factor_range = [\n",
    "                    factor + 0.1 * random.random() for factor in factor_range\n",
    "                ]\n",
    "\n",
    "                # 对每张图像应用不同大小的亮度因子\n",
    "                selected_factor = random.sample(factor_range, 3)\n",
    "                for factor in selected_factor:\n",
    "                    if (brightness * factor > 225) or (\n",
    "                        brightness * factor < 25\n",
    "                    ):  # 跳过过亮或过暗的情况\n",
    "                        continue\n",
    "                    if brightness > 200 and factor > 0.2:  # 跳过图像过亮且要变得太暗的情况\n",
    "                        continue\n",
    "                    if brightness < 50 and factor < 3.0:  # 跳过图像过暗且要变得太亮的情况\n",
    "                        continue\n",
    "                    if (\n",
    "                        nums > 10000 and (100 < brightness < 150) and (0.5 < factor < 2)\n",
    "                    ):  # 跳过图像太多并且图像亮度合适但变化较小的情况\n",
    "                        continue\n",
    "\n",
    "                    brightness_image = adjust_exposure(image, factor)\n",
    "                    new_file_name = f\"{os.path.splitext(os.path.basename(file_path))[0]}_brightness{factor:.2f}{os.path.splitext(file_path)[1]}\"\n",
    "                    new_file_path = os.path.join(\n",
    "                        new_folder_path, folder_name, new_file_name\n",
    "                    )\n",
    "\n",
    "                    if not os.path.exists(os.path.join(new_folder_path, folder_name)):\n",
    "                        os.makedirs(os.path.join(new_folder_path, folder_name))\n",
    "\n",
    "                    Image.fromarray(brightness_image).save(new_file_path)\n",
    "\n",
    "                    if nums > 5000:  # 图像太多的情况做一次亮度调整就够了\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/Users/WangHao/Sites/学习/Python/TuLiProject/TrainNetPipeline/datas/character_advance/nonchinese\"\n",
    "image_dict = gather_images(image_dir)\n",
    "\n",
    "brightness_dataset(image_dict, f\"{image_dir}_brightness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他模式（颜色抖动、噪声、遮挡、变换）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 噪声（方差越大，噪声越大，设置为0.01到0.05）\n",
    "def apply_add_noise(image: np.ndarray, threshold=15):\n",
    "    row, col, ch = image.shape\n",
    "    min_side = min([row, col])\n",
    "    var_range = [0.01, 0.008, 0.005, 0.003]\n",
    "    var = random.sample(var_range, 1)[0]\n",
    "    if min_side < threshold:\n",
    "        var = 0.003\n",
    "    mean = 0\n",
    "    sigma = var**0.5\n",
    "    gauss = np.random.normal(mean, sigma, (row, col, ch))\n",
    "    gauss = gauss.reshape(row, col, ch)\n",
    "    noisy = image.astype(np.float64) / 255 + gauss\n",
    "    noisy = np.clip(noisy, 0, 1) * 255\n",
    "    return noisy.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 颜色抖动\n",
    "def apply_color_jitter(image: np.ndarray, threshold=15):\n",
    "    min_side = min(image.shape[:2])\n",
    "    image = Image.fromarray(image)\n",
    "    if min_side < threshold:\n",
    "        factor = 0.3\n",
    "    else:\n",
    "        factor = 0.5\n",
    "    transform = transforms.ColorJitter(\n",
    "        brightness=1, contrast=factor, saturation=factor, hue=factor\n",
    "    )\n",
    "    jittered_image = np.array(transform(image))\n",
    "    return jittered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遮挡（遮挡值255为白色，0为黑色，128为灰色）\n",
    "def apply_occlusion(image: np.ndarray, threshold=15):\n",
    "    height, width, _ = image.shape\n",
    "    min_side = min(image.shape[:2])\n",
    "    min_area = height * width / 20\n",
    "    max_area = height * width / 10\n",
    "    if min_side < threshold:\n",
    "        min_area = min_area / 1.5\n",
    "        max_area = max_area / 1.5\n",
    "    while True:\n",
    "        if min_side < threshold:\n",
    "            x, y = np.random.randint(width), np.random.randint(height)\n",
    "        else:\n",
    "            x, y = np.random.randint(0, width - 2), np.random.randint(0, height - 2)\n",
    "        max_w, max_h = width - x, height - y\n",
    "        if min_side < threshold:\n",
    "            w, h = np.random.randint(1, max_w + 1), np.random.randint(1, max_h + 1)\n",
    "        else:\n",
    "            w, h = np.random.randint(3, max_w + 1), np.random.randint(3, max_h + 1)\n",
    "        if min_area <= w * h <= max_area:\n",
    "            break\n",
    "    mask_range = [5, 50, 100, 150, 200, 250]\n",
    "    mask = random.sample(mask_range, 1)[0]\n",
    "    image_copy = image.copy()\n",
    "    image_copy[y : y + h, x : x + w] = mask\n",
    "    return image_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仿射变换（旋转30度、平移0.1、缩放2、倾斜0.5）\n",
    "def apply_affine_transform(image: np.ndarray, threshold=15):\n",
    "    # 获取图像尺寸\n",
    "    height, width = image.shape[:2]\n",
    "    min_side = min(image.shape[:2])\n",
    "    # 计算旋转中心\n",
    "    center = (width / 2, height / 2)\n",
    "\n",
    "    # 参数随机化\n",
    "    angle = np.random.randint(-15, 16)\n",
    "    translate = (\n",
    "        np.random.randint(-width // 20, width // 20 + 1),\n",
    "        np.random.randint(-height // 10, height // 10 + 1),\n",
    "    )\n",
    "    scale = 0.85 + 0.3 * np.random.random()\n",
    "    shear = np.random.uniform(-0.3, 0.3)\n",
    "    if min_side < threshold:\n",
    "        angle = np.random.randint(-10, 11)\n",
    "        translate = (0, 0)\n",
    "        scale = 1\n",
    "        shear = np.random.uniform(-0.2, 0.2)\n",
    "\n",
    "    # 计算旋转矩阵\n",
    "    M_rotate = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    M_rotate = np.vstack([M_rotate, [0, 0, 1]])\n",
    "    # 计算倾斜变换矩阵\n",
    "    M_shear = np.array([[1, shear, 0], [0, 1, 0], [0, 0, 1]])\n",
    "    # 合并矩阵\n",
    "    M = np.dot(M_rotate, M_shear)\n",
    "    # 应用平移\n",
    "    M[:2, 2] += translate\n",
    "    # 应用仿射变换\n",
    "    M_affine = M[:2, :]\n",
    "    transformed = cv2.warpAffine(image, M_affine, (width, height))\n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/Users/WangHao/Sites/学习/Python/TuLiProject/TrainNetPipeline/datas/character_advance/chinese\"\n",
    "images_dict = gather_images(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_pil = Image.open(list(images_dict.values())[1][200])\n",
    "display(image_data_pil.size, image_data_pil)\n",
    "\n",
    "image_processed = apply_add_noise(np.array(image_data_pil), 15)\n",
    "display(Image.fromarray(image_processed))\n",
    "\n",
    "image_processed = apply_color_jitter(np.array(image_data_pil), 15)\n",
    "display(Image.fromarray(image_processed))\n",
    "\n",
    "image_processed = apply_occlusion(np.array(image_data_pil), 15)\n",
    "display(Image.fromarray(image_processed))\n",
    "\n",
    "image_processed = apply_affine_transform(np.array(image_data_pil), 15)\n",
    "display(Image.fromarray(image_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对数据集中的所有图像应用其他模式处理\n",
    "def other_dataset(image_dict, new_folder_path):\n",
    "    for folder_name, file_paths in image_dict.items():\n",
    "        if folder_name not in [\"chinese\", \"nonchinese\"]:\n",
    "            nums = len(file_paths)\n",
    "            k = 0\n",
    "            for idx, file_path in enumerate(file_paths):\n",
    "                image = np.array(Image.open(file_path))\n",
    "                if not os.path.exists(os.path.join(new_folder_path, folder_name)):\n",
    "                    os.makedirs(os.path.join(new_folder_path, folder_name))\n",
    "\n",
    "                if nums > 4000:\n",
    "                    if nums > 16000:\n",
    "                        if idx % 8 != 0:  # 当 nums > 16000 时，只有当 idx 是 8 的倍数时才不跳过\n",
    "                            continue\n",
    "                    elif nums > 8000:\n",
    "                        if (\n",
    "                            idx % 4 != 0\n",
    "                        ):  # 当 nums > 8000 但不超过 16000 时，只有当 idx 是 4 的倍数时才不跳过\n",
    "                            continue\n",
    "                    elif idx % 2 == 0:  # 当 nums > 4000 但不超过 8000 时，只有当 idx 是偶数时才跳过\n",
    "                        continue\n",
    "\n",
    "                noise_image = apply_add_noise(image, 15)\n",
    "                k += 1\n",
    "                new_file_name = f\"{os.path.splitext(os.path.basename(file_path))[0]}_other{k}{os.path.splitext(file_path)[1]}\"\n",
    "                new_file_path = os.path.join(\n",
    "                    new_folder_path, folder_name, new_file_name\n",
    "                )\n",
    "                Image.fromarray(noise_image).save(new_file_path)\n",
    "\n",
    "                jitter_image = apply_color_jitter(image, 15)\n",
    "                k += 1\n",
    "                new_file_name = f\"{os.path.splitext(os.path.basename(file_path))[0]}_other{k}{os.path.splitext(file_path)[1]}\"\n",
    "                new_file_path = os.path.join(\n",
    "                    new_folder_path, folder_name, new_file_name\n",
    "                )\n",
    "                Image.fromarray(jitter_image).save(new_file_path)\n",
    "\n",
    "                occlusion_image = apply_occlusion(image, 15)\n",
    "                k += 1\n",
    "                new_file_name = f\"{os.path.splitext(os.path.basename(file_path))[0]}_other{k}{os.path.splitext(file_path)[1]}\"\n",
    "                new_file_path = os.path.join(\n",
    "                    new_folder_path, folder_name, new_file_name\n",
    "                )\n",
    "                Image.fromarray(occlusion_image).save(new_file_path)\n",
    "\n",
    "                transform_image = apply_affine_transform(image, 15)\n",
    "                k += 1\n",
    "                new_file_name = f\"{os.path.splitext(os.path.basename(file_path))[0]}_other{k}{os.path.splitext(file_path)[1]}\"\n",
    "                new_file_path = os.path.join(\n",
    "                    new_folder_path, folder_name, new_file_name\n",
    "                )\n",
    "                Image.fromarray(transform_image).save(new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/Users/WangHao/Sites/学习/Python/TuLiProject/TrainNetPipeline/datas/character_advance/nonchinese\"\n",
    "image_dict = gather_images(image_dir)\n",
    "\n",
    "other_dataset(image_dict, f\"{image_dir}_other\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
