{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TensorFlow 版本1.x阶段，神经网络模型标准构建流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m y_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msquare(x_data) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(\u001b[39m0\u001b[39m, \u001b[39m0.05\u001b[39m, x_data\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      9\u001b[0m \u001b[39m# 定义输入数据属性\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m xs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mplaceholder(tf\u001b[39m.\u001b[39mfloat32, [\u001b[39mNone\u001b[39;00m, \u001b[39m1\u001b[39m])\n\u001b[1;32m     11\u001b[0m ys \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mplaceholder(tf\u001b[39m.\u001b[39mfloat32, [\u001b[39mNone\u001b[39;00m, \u001b[39m1\u001b[39m])\n\u001b[1;32m     14\u001b[0m \u001b[39m# 定义模型层函数\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 构建神经网络并训练，使模型拟合 y=x^2+1\n",
    "# 创建输入数据与标签数据\n",
    "x_data = np.linspace(-1, 1, 300)[:, np.newaxis]\n",
    "y_data = np.square(x_data) + 1 + np.random.normal(0, 0.05, x_data.shape)\n",
    "\n",
    "# 定义输入数据属性\n",
    "xs = tf.placeholder(tf.float32, [None, 1])\n",
    "ys = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "\n",
    "# 定义模型层函数\n",
    "def model_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    \"\"\"\n",
    "    :param inputs: 数据输入\n",
    "    :param in_size: 输入大小\n",
    "    :param out_size: 输出大小\n",
    "    :param activation_function: 激活函数（默认没有）\n",
    "    :return:output：数据输出\n",
    "    \"\"\"\n",
    "    weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "    w_mul_x_add_b = tf.matmul(inputs, weights) + biases\n",
    "\n",
    "    # 根据是否有激活函数\n",
    "    if activation_function is None:\n",
    "        output = w_mul_x_add_b\n",
    "    else:\n",
    "        output = activation_function(w_mul_x_add_b)\n",
    "    return output\n",
    "\n",
    "\n",
    "# 定义一个隐藏层\n",
    "hidden_layer1 = model_layer(xs, 1, 10, activation_function=tf.nn.relu)\n",
    "\n",
    "# 定义一个输出层\n",
    "output_layer1 = model_layer(hidden_layer1, 10, 1)\n",
    "\n",
    "# 定义全局变量初始化 (在计算图中且被存储的变量，tf.local_variables_initializer()是在计算图中但未被存储的变量)\n",
    "init_weight = tf.global_variables_initializer()\n",
    "\n",
    "# 定义损失函数\n",
    "loss = tf.reduce_mean(\n",
    "    tf.reduce_sum(tf.square(ys - output_layer1), reduction_indices=[1])\n",
    ")\n",
    "\n",
    "# 定义训练过程\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "# tf.Session()通过启动一个tf后端会话来处理定义的操作\n",
    "# 执行全局变量初始化\n",
    "session = tf.Session()\n",
    "session.run(init_weight)\n",
    "\n",
    "# 执行训练过程\n",
    "for i in range(1000):\n",
    "    session.run(train_step, feed_dict={xs: x_data, ys: y_data})\n",
    "    if i % 100 == 0:\n",
    "        print(session.run(loss, feed_dict={xs: x_data, ys: y_data}))\n",
    "\n",
    "# 结果关闭会话\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 版本2.x阶段，神经网络模型标准构建流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "# 构建神经网络并训练，使模型对图片分类\n",
    "# 第一阶段数据准备\n",
    "# 导入数据集\n",
    "def load_data():\n",
    "    dirname = os.path.join(\"datasets\", \"fashion-mnist\")\n",
    "    files = [\n",
    "        \"train-labels-idx1-ubyte.gz\",\n",
    "        \"train-images-idx3-ubyte.gz\",\n",
    "        \"t10k-labels-idx1-ubyte.gz\",\n",
    "        \"t10k-images-idx3-ubyte.gz\",\n",
    "    ]\n",
    "\n",
    "    paths = []\n",
    "    for fname in files:\n",
    "        paths.append(os.path.join(dirname, fname))\n",
    "\n",
    "    with gzip.open(paths[0], \"rb\") as lbpath:\n",
    "        y_train = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "\n",
    "    with gzip.open(paths[1], \"rb\") as imgpath:\n",
    "        x_train = np.frombuffer(imgpath.read(), np.uint8, offset=16).reshape(\n",
    "            len(y_train), 28, 28\n",
    "        )\n",
    "\n",
    "    with gzip.open(paths[2], \"rb\") as lbpath:\n",
    "        y_test = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "\n",
    "    with gzip.open(paths[3], \"rb\") as imgpath:\n",
    "        x_test = np.frombuffer(imgpath.read(), np.uint8, offset=16).reshape(\n",
    "            len(y_test), 28, 28\n",
    "        )\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "\n",
    "label_class = {\n",
    "    0: \"T-shirt/top\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\",\n",
    "}\n",
    "\n",
    "# 划分训练数据与测试数据\n",
    "(train_images, train_labels), (test_images, test_labels) = load_data()\n",
    "\n",
    "# 数据归一化 0~1 并结构化 [b w h c]\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "train_images = train_images[..., tf.newaxis].astype(\"float32\")\n",
    "test_images = test_images[..., tf.newaxis].astype(\"float32\")\n",
    "train_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "    .shuffle(buffer_size=60000)\n",
    "    .batch(32)\n",
    ")\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(32)\n",
    "\n",
    "for X, y in test_ds:\n",
    "    print(f\"Shape of X [N, H, W, C]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "\n",
    "# 数据可视化\n",
    "visual_data = False\n",
    "if visual_data:\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "        plt.xlabel(label_class[train_labels[i]])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 第二阶段构建模型\n",
    "# 定义模型类\n",
    "class MyModel(Model):\n",
    "    def get_config(self):\n",
    "        pass\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32, 3, activation=\"relu\")\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.d1 = tf.keras.layers.Dense(128, activation=\"relu\")\n",
    "        self.d2 = tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        x = self.d2(x)\n",
    "        output = x\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "# 实例化模型\n",
    "model = MyModel()\n",
    "\n",
    "# 定义优化器与损失函数\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# 定义训练损失与准确性记录容器\n",
    "train_loss_mean = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")\n",
    "\n",
    "# 定义测试损失与准确性记录容器\n",
    "test_loss_mean = tf.keras.metrics.Mean(name=\"test_loss\")\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"test_accuracy\")\n",
    "\n",
    "\n",
    "# 计算训练集的梯度和损失\n",
    "@tf.function\n",
    "def train_step(image, label):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(image, training=True)\n",
    "        train_loss = loss_function(label, predictions)\n",
    "    gradients = tape.gradient(train_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss_mean(train_loss)\n",
    "    train_accuracy(label, predictions)\n",
    "\n",
    "\n",
    "# 计算测试集的损失\n",
    "@tf.function\n",
    "def test_step(image, label):\n",
    "    predictions = model(image, training=False)\n",
    "    tt_ls = loss_function(label, predictions)\n",
    "\n",
    "    test_loss_mean(tt_ls)\n",
    "    test_accuracy(label, predictions)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 第三阶段运行策略\n",
    "    num_epochs = 200\n",
    "    with tf.device(\"/GPU:0\"):\n",
    "        for epoch in range(num_epochs):\n",
    "            start_time = time.time_ns()\n",
    "            train_loss_mean.reset_states()\n",
    "            train_accuracy.reset_states()\n",
    "            test_loss_mean.reset_states()\n",
    "            test_accuracy.reset_states()\n",
    "\n",
    "            for images, labels in train_ds:\n",
    "                train_step(images, labels)\n",
    "\n",
    "            for test_images, test_labels in train_ds:\n",
    "                test_step(test_images, test_labels)\n",
    "\n",
    "            end_time = time.time_ns()\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1}, \"\n",
    "                f\"Loss:{train_loss_mean.result() : .8f}, \"\n",
    "                f\"Accuracy:{train_accuracy.result() * 100 : .2f}%, \"\n",
    "                f\"Test Loss:{test_loss_mean.result() : .8f}, \"\n",
    "                f\"Test Accuracy:{test_accuracy.result() * 100 : .2f}%, \"\n",
    "                f\"Take time:{(end_time-start_time) / 1e9 : .4f}s\"\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7567524e79b96d316162151a38259d28be4bc298929f85b9103bf7fbca02c0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
