{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model was loaded from https://hf.co/models\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "LANGS = [\"ace_Arab\", \"eng_Latn\", \"fra_Latn\", \"spa_Latn\"]\n",
    "\n",
    "def translate(text, src_lang, tgt_lang):\n",
    "    \"\"\"\n",
    "    Translate the text from source lang to target lang\n",
    "    \"\"\"\n",
    "    translation_pipeline = pipeline(\"translation\", model=model, tokenizer=tokenizer, src_lang=src_lang, tgt_lang=tgt_lang, max_length=400, device=device)\n",
    "    result = translation_pipeline(text)\n",
    "    return result[0]['translation_text']\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=translate,\n",
    "    inputs=[\n",
    "        gr.components.Textbox(label=\"Text\"),\n",
    "        gr.components.Dropdown(label=\"Source Language\", choices=LANGS),\n",
    "        gr.components.Dropdown(label=\"Target Language\", choices=LANGS),\n",
    "    ],\n",
    "    outputs=[\"text\"],\n",
    "    examples=[[\"Building a translation demo with Gradio is so easy!\", \"eng_Latn\", \"spa_Latn\"]],\n",
    "    cache_examples=False,\n",
    "    title=\"Translation Demo\",\n",
    "    description=\"This demo is a simplified version of the original [NLLB-Translator](https://huggingface.co/spaces/Narrativaai/NLLB-Translator) space\"\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
