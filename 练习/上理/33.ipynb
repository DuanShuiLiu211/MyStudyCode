{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. ***loss function bce***\n",
    "***F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)***\n",
    "- weight (Tensor, optional): a manual rescaling weight given to the loss of each batch element.\n",
    "- If given, has to be a Tensor of size `nbatch`.\n",
    "\n",
    "***The unreduced (i.e. with `reduction` set to ``'none'``) loss can be described as***\n",
    "\n",
    "$$\n",
    "\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
    "l_n = - w_n \\left[ y_n \\cdot \\log x_n + (1 - y_n) \\cdot \\log (1 - x_n) \\right],\n",
    "$$\n",
    "\n",
    "`N` is the batch size.\n",
    "\n",
    "***If `reduction` is not ``'none'`` (default ``'mean'``), then***\n",
    "\n",
    "$$\n",
    "\\ell(x, y) = \\begin{cases}\n",
    "\\operatorname{mean}(L), \\quad & \\text{if reduction} = \\text{`mean';}\\\\\n",
    "\\operatorname{sum}(L), \\quad & \\text{if reduction} = \\text{`sum'.}\n",
    "\\end{cases}\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bce = nn.BCELoss()\n",
    "\n",
    "def binary_cross_entorpy_np(inputs, targets):\n",
    "    inputs = inputs.numpy()\n",
    "    inputs = inputs.reshape((inputs.shape[0]*inputs.shape[1], inputs.shape[-2]*inputs.shape[-1]))\n",
    "    targets = targets.numpy()\n",
    "    targets = targets.reshape((targets.shape[0]*targets.shape[1], targets.shape[-2]*targets.shape[-1]))\n",
    "    outputs = 0.\n",
    "    weight = 1.\n",
    "    for i in range(targets.shape[0]):\n",
    "        temp = 0\n",
    "        for j in range(targets.shape[1]):\n",
    "            temp += -1. * weight * (targets[i, j]*np.log(inputs[i, j]) + (1-targets[i, j])*np.log(1-inputs[i, j]))\n",
    "        outputs += (temp / targets.shape[1])\n",
    "    return np.around(outputs / targets.shape[0], 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = torch.rand((1, 2, 2, 2))\n",
    "b = torch.tensor([[[[0, 1.], [1., 0]], [[0, 1.], [1., 0]]]])\n",
    "binary_cross_entorpy_np(a, b)\n",
    "print(a, b, bce(a, b), binary_cross_entorpy_np(a, b), sep=\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. ***loss function ce***\n",
    "***F.cross_entropy(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction, label_smoothing=self.label_smoothing)***\n",
    "- this case is equivalent to the combination of `~torch.nn.LogSoftmax` and `~torch.nn.NLLLoss`.\n",
    "- It is useful when training a classification problem with `C` classes.\n",
    "- If provided, the optional argument `weight` should be a 1D `Tensor` assigning weight to each of the classes, This is\n",
    "particularly useful when you have an unbalanced training set.\n",
    "\n",
    "***The `input` is expected to contain raw, unnormalized scores for each class.***\n",
    "- `input` has to be a Tensor of size `(C)` for unbatched input, `(minibatch, C)` or `(minibatch, C, d_1, d_2, ..., d_K)` with `K\n",
    "\\geq 1` for the `K`-dimensional case.\n",
    "- The last being useful for higher dimension inputs, such as computing cross entropy loss per-pixel for 2D images.\n",
    "\n",
    "***The `target` that this criterion expects should contain either***\n",
    "- Class indices in the range `[0, C)` where `C` is the number of classes, not one-hot.\n",
    "- if `ignore_index` is specified, loss also accepts this class index (this index may not necessarily be in the class range).\n",
    "- If containing class probabilities, same shape as the input and each value should be between `[0, 1]`.\n",
    "- The unreduced (i.e. with `reduction` set to ``'none'``) loss for this case can be described as\n",
    "\n",
    "$$\n",
    "\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
    "l_n = - w_{y_n} \\log \\frac{\\exp(x_{n,y_n})}{\\sum_{c=1}^C \\exp(x_{n,c})}\n",
    "\\cdot \\mathbb{1}\\{y_n \\not= \\text{ignore\\_index}\\}\n",
    "$$\n",
    "\n",
    "`x` is the input, `y` is the target, `w` is the weight,\n",
    "`C` is the number of classes, and `N` spans the minibatch dimension as well as `d_1, ..., d_k` for the `K`-dimensional case.\n",
    "\n",
    "***If `reduction` is not ``'none'`` (default ``'mean'``), then***\n",
    "\n",
    "$$\n",
    "\\ell(x, y) = \\begin{cases}\n",
    "  \\sum_{n=1}^N \\frac{1}{\\sum_{n=1}^N w_{y_n} \\cdot \\mathbb{1}\\{y_n \\not= \\text{ignore\\_index}\\}} l_n, \\quad &\n",
    "   \\text{if reduction} = \\text{`mean';}\\\\\n",
    "    \\sum_{n=1}^N l_n, \\quad &\n",
    "    \\text{if reduction} = \\text{`sum'.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "- Probabilities for each class; useful when labels beyond a single class per minibatch item\n",
    "  are required, such as for blended labels, label smoothing, etc. The unreduced (i.e. with\n",
    "  `reduction` set to ``'none'``) loss for this case can be described as\n",
    "\n",
    "$$\n",
    "\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
    "l_n = - \\sum_{c=1}^C w_c \\log \\frac{\\exp(x_{n,c})}{\\sum_{i=1}^C \\exp(x_{n,i})} y_{n,c}\n",
    "$$\n",
    "\n",
    "`x` is the input, `y` is the target, `w` is the weight,\n",
    "`C` is the number of classes, and `N` spans the minibatch dimension as well as `d_1, ..., d_k` for the `K`-dimensional case.\n",
    "\n",
    "***If `reduction` is not ``'none'`` (default ``'mean'``), then***\n",
    "\n",
    "$$\n",
    "\\ell(x, y) = \\begin{cases}\n",
    "  \\frac{\\sum_{n=1}^N l_n}{N}, \\quad &\n",
    "   \\text{if reduction} = \\text{`mean';}\\\\\n",
    "    \\sum_{n=1}^N l_n, \\quad &\n",
    "    \\text{if reduction} = \\text{`sum'.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "- The performance of this criterion is generally better when `target` contains class\n",
    "  indices, as this allows for optimized computation. Consider providing `target` as\n",
    "  class probabilities only when a single class label per minibatch item is too restrictive.\n",
    "\n",
    "***The `output` If reduction is 'none', same shape as the target. Otherwise, scalar.***"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ce = nn.CrossEntropyLoss()\n",
    "\n",
    "ls = nn.LogSoftmax(dim=1)\n",
    "nll = nn.NLLLoss()\n",
    "\n",
    "def cross_entorpy_np(inputs, targets):\n",
    "    inputs = inputs.numpy()\n",
    "    inputs = inputs.reshape((inputs.shape[0], inputs.shape[1], inputs.shape[-2]*inputs.shape[-1]))\n",
    "    targets = targets.numpy()\n",
    "    targets = targets.reshape((targets.shape[0], targets.shape[1], targets.shape[-2]*targets.shape[-1]))\n",
    "    outputs = 0.\n",
    "    weight = 1.\n",
    "    for i in range(targets.shape[0]):\n",
    "        temp = 0\n",
    "        for j in range(targets.shape[1]):\n",
    "            temp += -1. * weight * np.log((np.exp(inputs[i, j, :])[targets[i, j, :]] / np.sum(np.exp(inputs[i, j, :]))))\n",
    "        outputs += (temp / targets.shape[1])\n",
    "    return np.around(outputs / targets.shape[0], 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inputs = torch.Tensor([[[[0.1234, 0.5555, 0.3211]], [[0.1234, 0.5555, 0.3211]], [[0.1234, 0.5555, 0.3211]]]])\n",
    "targets = torch.tensor([[[[0, 1, 2]]]])\n",
    "\n",
    "outputs = ce(inputs, targets)\n",
    "print(outputs)\n",
    "\n",
    "# outputs = nll(ls(inputs), targets)\n",
    "# print(outputs)\n",
    "\n",
    "outputs = cross_entorpy_np(inputs, targets)\n",
    "print(outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = np.random.rand(1, 2, 2, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a.flatten((-2, -1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "b = a.reshape(2, 4)\n",
    "b.shape\n",
    "b.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.log(0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input=torch.Tensor([[0.1234, 0.5555,0.3211],[0.1234, 0.5555,0.3211],[0.1234, 0.5555,0.3211],])\n",
    "target = torch.tensor([0,1,2])\n",
    "input[0][target[0]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator = torch.Generator(device=\"cpu\").manual_seed(51)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.rand(5, generator=generator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.rand(5, generator=generator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator(device=\"cpu\").manual_seed(51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9486, 0.0251, 0.1548, 0.4304, 0.5786])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(5, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6319, 0.9800, 0.8547, 0.7153, 0.5669])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(5, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7567524e79b96d316162151a38259d28be4bc298929f85b9103bf7fbca02c0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}