{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "import medpy.metric as medmetric\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from skimage import morphology\n",
    "from matplotlib import pyplot as plot\n",
    "import pandas as pd\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算狭窄率\n",
    "- 对mask进行腐蚀操作，去掉外膜得到正常血管壁的厚度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"label\"\n",
    "result_dir = f'/Volumes/昊大侠/工作/实习相关/微创卜算子医疗科技有限公司/陈嘉懿组/数据/短轴动态狭窄率/result/狭窄率图表_0920/{model_name}'\n",
    "file_list = os.listdir(result_dir)\n",
    "try:\n",
    "    file_list.remove(\".DS_Store\")\n",
    "except ValueError:\n",
    "    pass\n",
    "try:\n",
    "    file_list.remove(\"._.DS_Store\")\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "spacing_pixels = np.array(\n",
    "    pd.read_excel(\"/Users/WangHao/Desktop/TODO/Data/动态测试集spacing.xlsx\").values)\n",
    "\n",
    "pn_all = {}\n",
    "pne_all = {}\n",
    "mask_all = {}\n",
    "for idx, file_name in enumerate(file_list):\n",
    "    if file_name.endswith(\".nii.gz\"):\n",
    "        data = sitk.GetArrayFromImage(\n",
    "            sitk.ReadImage(os.path.join(result_dir, file_name)))\n",
    "    elif file_name.endswith(\".npy\"):\n",
    "        data = np.load(os.path.join(result_dir, file_name), allow_pickle=True)\n",
    "    else:\n",
    "        print(f\"data format {os.path.splitext(file_name)[-1]} is error\")\n",
    "        sys.exit()\n",
    "\n",
    "    spacing = int(spacing_pixels[np.argwhere(\n",
    "        spacing_pixels[:, 0] == file_name[:-7])][0][0][1])\n",
    "\n",
    "    pn = []\n",
    "    pne = []\n",
    "    mask = {}\n",
    "    mask_out_list = []\n",
    "    mask_in_list = []\n",
    "    mask_both_list = []\n",
    "    mask_both_erode_list = []\n",
    "    for k, img in enumerate(data):\n",
    "        # pred 腐蚀\n",
    "        out_mask = np.zeros_like(img)\n",
    "        out_mask[img == 1] = 1  # 环形mask\n",
    "        in_mask = np.zeros_like(img)\n",
    "        in_mask[img == 2] = 1  # 内膜mask\n",
    "        both_mask = out_mask + in_mask  # 外膜mask\n",
    "        both_mask_erode = cv2.erode(both_mask,\n",
    "                                    kernel=(3, 3),\n",
    "                                    iterations=spacing // 10)  # 外膜腐蚀mask\n",
    "\n",
    "        mask_out_list.append(out_mask)\n",
    "        mask_in_list.append(in_mask)\n",
    "        mask_both_list.append(both_mask)\n",
    "        mask_both_erode_list.append(both_mask_erode)\n",
    "\n",
    "        pred_narrow = 1 - (np.sum(in_mask) / np.sum(both_mask))\n",
    "        pred_erode_narrow = 1 - (np.sum(in_mask) / np.sum(both_mask_erode))\n",
    "\n",
    "        pn.append(pred_narrow)\n",
    "        pne.append(pred_erode_narrow)\n",
    "\n",
    "        if False:\n",
    "            print(\n",
    "                f'pred_narrow:{pred_narrow:.2f} | pred_narrow:{pred_erode_narrow:.2f}'\n",
    "            )\n",
    "\n",
    "    mask[\"out\"] = mask_out_list\n",
    "    mask[\"in\"] = mask_in_list\n",
    "    mask[\"both\"] = mask_both_list\n",
    "    mask[\"both_erode\"] = mask_both_erode_list\n",
    "\n",
    "    mask_all[file_name] = mask\n",
    "    pn_all[file_name] = pd.Series(pn)\n",
    "    pne_all[file_name] = pd.Series(pne)\n",
    "\n",
    "if True:\n",
    "    with pd.ExcelWriter(f'{model_name}.xlsx') as writer:\n",
    "        df_pn_all = pd.DataFrame(data=pn_all)\n",
    "        df_pn_all.to_excel(writer,\n",
    "                           sheet_name=\"diameter stenosis\",\n",
    "                           index=True,\n",
    "                           header=True,\n",
    "                           startrow=0,\n",
    "                           startcol=0)\n",
    "\n",
    "    with pd.ExcelWriter(f'{model_name}_erode.xlsx') as writer:\n",
    "        df_pne_all = pd.DataFrame(data=pne_all)\n",
    "        df_pne_all.to_excel(writer,\n",
    "                            sheet_name=\"diameter stenosis\",\n",
    "                            index=True,\n",
    "                            header=True,\n",
    "                            startrow=0,\n",
    "                            startcol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"3dunet\"\n",
    "result_dir = f'/Volumes/昊大侠/工作/实习相关/微创卜算子医疗科技有限公司/陈嘉懿组/数据/短轴动态狭窄率/result/狭窄率图表_0920/{model_name}'\n",
    "file_list = os.listdir(result_dir)\n",
    "try:\n",
    "    file_list.remove(\".DS_Store\")\n",
    "except ValueError:\n",
    "    pass\n",
    "try:\n",
    "    file_list.remove(\"._.DS_Store\")\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "spacing_pixels = np.array(\n",
    "    pd.read_excel(\"/Users/WangHao/Desktop/TODO/Data/动态测试集spacing.xlsx\").values)\n",
    "\n",
    "pn_3dunet_all = {}\n",
    "pne_3dunet_all = {}\n",
    "mask_3dunet_all = {}\n",
    "for idx, file_name in enumerate(file_list):\n",
    "    if file_name.endswith(\".nii.gz\"):\n",
    "        data = sitk.GetArrayFromImage(\n",
    "            sitk.ReadImage(os.path.join(result_dir, file_name)))\n",
    "    elif file_name.endswith(\".npy\"):\n",
    "        data = np.load(os.path.join(result_dir, file_name), allow_pickle=True)\n",
    "    else:\n",
    "        print(f\"data format {os.path.splitext(file_name)[-1]} is error\")\n",
    "        sys.exit()\n",
    "\n",
    "    spacing = int(spacing_pixels[np.argwhere(\n",
    "        spacing_pixels[:, 0] == file_name[:-7])][0][0][1])\n",
    "\n",
    "    pn = []\n",
    "    pne = []\n",
    "    mask = {}\n",
    "    mask_out_list = []\n",
    "    mask_in_list = []\n",
    "    mask_both_list = []\n",
    "    mask_both_erode_list = []\n",
    "    for k, img in enumerate(data):\n",
    "        # pred 腐蚀\n",
    "        out_mask = np.zeros_like(img)\n",
    "        out_mask[img == 1] = 1  # 环形mask\n",
    "        in_mask = np.zeros_like(img)\n",
    "        in_mask[img == 2] = 1  # 内膜mask\n",
    "        both_mask = out_mask + in_mask  # 外膜mask\n",
    "        both_mask_erode = cv2.erode(both_mask,\n",
    "                                    kernel=(3, 3),\n",
    "                                    iterations=spacing // 10)  # 外膜腐蚀mask\n",
    "\n",
    "        mask_out_list.append(out_mask)\n",
    "        mask_in_list.append(in_mask)\n",
    "        mask_both_list.append(both_mask)\n",
    "        mask_both_erode_list.append(both_mask_erode)\n",
    "\n",
    "        pred_narrow = 1 - (np.sum(in_mask) / np.sum(both_mask))\n",
    "        pred_erode_narrow = 1 - (np.sum(in_mask) / np.sum(both_mask_erode))\n",
    "\n",
    "        pn.append(pred_narrow)\n",
    "        pne.append(pred_erode_narrow)\n",
    "\n",
    "        if False:\n",
    "            print(\n",
    "                f'pred_narrow:{pred_narrow:.2f} | pred_narrow:{pred_erode_narrow:.2f}'\n",
    "            )\n",
    "\n",
    "    mask[\"out\"] = mask_out_list\n",
    "    mask[\"in\"] = mask_in_list\n",
    "    mask[\"both\"] = mask_both_list\n",
    "    mask[\"both_erode\"] = mask_both_erode_list\n",
    "\n",
    "    mask_3dunet_all[file_name] = mask\n",
    "    pn_3dunet_all[file_name] = pd.Series(pn)\n",
    "    pne_3dunet_all[file_name] = pd.Series(pne)\n",
    "\n",
    "if True:\n",
    "    with pd.ExcelWriter(f'{model_name}.xlsx') as writer:\n",
    "        df_pn_all = pd.DataFrame(data=pn_3dunet_all)\n",
    "        df_pn_all.to_excel(writer,\n",
    "                           sheet_name=\"diameter stenosis\",\n",
    "                           index=True,\n",
    "                           header=True,\n",
    "                           startrow=0,\n",
    "                           startcol=0)\n",
    "\n",
    "    with pd.ExcelWriter(f'{model_name}_erode.xlsx') as writer:\n",
    "        df_pne_all = pd.DataFrame(data=pne_3dunet_all)\n",
    "        df_pne_all.to_excel(writer,\n",
    "                            sheet_name=\"diameter stenosis\",\n",
    "                            index=True,\n",
    "                            header=True,\n",
    "                            startrow=0,\n",
    "                            startcol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"rvm\"\n",
    "result_dir = f'/Volumes/昊大侠/工作/实习相关/微创卜算子医疗科技有限公司/陈嘉懿组/数据/短轴动态狭窄率/result/狭窄率图表_0920/{model_name}'\n",
    "file_list = os.listdir(result_dir)\n",
    "try:\n",
    "    file_list.remove(\".DS_Store\")\n",
    "except ValueError:\n",
    "    pass\n",
    "try:\n",
    "    file_list.remove(\"._.DS_Store\")\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "spacing_pixels = np.array(\n",
    "    pd.read_excel(\"/Users/WangHao/Desktop/TODO/Data/动态测试集spacing.xlsx\").values)\n",
    "\n",
    "pn_rvm_all = {}\n",
    "pne_rvm_all = {}\n",
    "mask_rvm_all = {}\n",
    "for idx, file_name in enumerate(file_list):\n",
    "    if file_name.endswith(\".nii.gz\"):\n",
    "        data = sitk.GetArrayFromImage(\n",
    "            sitk.ReadImage(os.path.join(result_dir, file_name)))\n",
    "    elif file_name.endswith(\".npy\"):\n",
    "        data = np.load(os.path.join(result_dir, file_name), allow_pickle=True)\n",
    "    else:\n",
    "        print(f\"data format {os.path.splitext(file_name)[-1]} is error\")\n",
    "        sys.exit()\n",
    "\n",
    "    spacing = int(spacing_pixels[np.argwhere(\n",
    "        spacing_pixels[:, 0] == file_name[:-7])][0][0][1])\n",
    "\n",
    "    pn = []\n",
    "    pne = []\n",
    "    mask = {}\n",
    "    mask_out_list = []\n",
    "    mask_in_list = []\n",
    "    mask_both_list = []\n",
    "    mask_both_erode_list = []\n",
    "    for k, img in enumerate(data):\n",
    "        # pred 腐蚀\n",
    "        out_mask = np.zeros_like(img)\n",
    "        out_mask[img == 1] = 1  # 环形mask\n",
    "        in_mask = np.zeros_like(img)\n",
    "        in_mask[img == 2] = 1  # 内膜mask\n",
    "        both_mask = out_mask + in_mask  # 外膜mask\n",
    "        both_mask_erode = cv2.erode(both_mask,\n",
    "                                    kernel=(3, 3),\n",
    "                                    iterations=spacing // 10)  # 外膜腐蚀mask\n",
    "\n",
    "        mask_out_list.append(out_mask)\n",
    "        mask_in_list.append(in_mask)\n",
    "        mask_both_list.append(both_mask)\n",
    "        mask_both_erode_list.append(both_mask_erode)\n",
    "\n",
    "        pred_narrow = 1 - (np.sum(in_mask) / np.sum(both_mask))\n",
    "        pred_erode_narrow = 1 - (np.sum(in_mask) / np.sum(both_mask_erode))\n",
    "\n",
    "        pn.append(pred_narrow)\n",
    "        pne.append(pred_erode_narrow)\n",
    "\n",
    "        if False:\n",
    "            print(\n",
    "                f'pred_narrow:{pred_narrow:.2f} | pred_narrow:{pred_erode_narrow:.2f}'\n",
    "            )\n",
    "\n",
    "    mask[\"out\"] = mask_out_list\n",
    "    mask[\"in\"] = mask_in_list\n",
    "    mask[\"both\"] = mask_both_list\n",
    "    mask[\"both_erode\"] = mask_both_erode_list\n",
    "\n",
    "    mask_rvm_all[file_name] = mask\n",
    "    pn_rvm_all[file_name] = pd.Series(pn)\n",
    "    pne_rvm_all[file_name] = pd.Series(pne)\n",
    "\n",
    "if True:\n",
    "    with pd.ExcelWriter(f'{model_name}.xlsx') as writer:\n",
    "        df_pn_all = pd.DataFrame(data=pn_rvm_all)\n",
    "        df_pn_all.to_excel(writer,\n",
    "                           sheet_name=\"diameter stenosis\",\n",
    "                           index=True,\n",
    "                           header=True,\n",
    "                           startrow=0,\n",
    "                           startcol=0)\n",
    "\n",
    "    with pd.ExcelWriter(f'{model_name}_erode.xlsx') as writer:\n",
    "        df_pne_all = pd.DataFrame(data=pne_rvm_all)\n",
    "        df_pne_all.to_excel(writer,\n",
    "                            sheet_name=\"diameter stenosis\",\n",
    "                            index=True,\n",
    "                            header=True,\n",
    "                            startrow=0,\n",
    "                            startcol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"transbts\"\n",
    "result_dir = f'/Volumes/昊大侠/工作/实习相关/微创卜算子医疗科技有限公司/陈嘉懿组/数据/短轴动态狭窄率/result/狭窄率图表_0920/{model_name}'\n",
    "file_list = os.listdir(result_dir)\n",
    "try:\n",
    "    file_list.remove(\".DS_Store\")\n",
    "except ValueError:\n",
    "    pass\n",
    "try:\n",
    "    file_list.remove(\"._.DS_Store\")\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "spacing_pixels = np.array(\n",
    "    pd.read_excel(\"/Users/WangHao/Desktop/TODO/Data/动态测试集spacing.xlsx\").values)\n",
    "\n",
    "pn_transbts_all = {}\n",
    "pne_transbts_all = {}\n",
    "mask_transbts_all = {}\n",
    "for idx, file_name in enumerate(file_list):\n",
    "    if file_name.endswith(\".nii.gz\"):\n",
    "        data = sitk.GetArrayFromImage(\n",
    "            sitk.ReadImage(os.path.join(result_dir, file_name)))\n",
    "    elif file_name.endswith(\".npy\"):\n",
    "        data = np.load(os.path.join(result_dir, file_name), allow_pickle=True)\n",
    "    else:\n",
    "        print(f\"data format {os.path.splitext(file_name)[-1]} is error\")\n",
    "        sys.exit()\n",
    "\n",
    "    spacing = int(spacing_pixels[np.argwhere(\n",
    "        spacing_pixels[:, 0] == file_name[:-7])][0][0][1])\n",
    "\n",
    "    pn = []\n",
    "    pne = []\n",
    "    mask = {}\n",
    "    mask_out_list = []\n",
    "    mask_in_list = []\n",
    "    mask_both_list = []\n",
    "    mask_both_erode_list = []\n",
    "    for k, img in enumerate(data):\n",
    "        # pred 腐蚀\n",
    "        out_mask = np.zeros_like(img)\n",
    "        out_mask[img == 1] = 1  # 环形mask\n",
    "        in_mask = np.zeros_like(img)\n",
    "        in_mask[img == 2] = 1  # 内膜mask\n",
    "        both_mask = out_mask + in_mask  # 外膜mask\n",
    "        both_mask_erode = cv2.erode(both_mask,\n",
    "                                    kernel=(3, 3),\n",
    "                                    iterations=spacing // 10)  # 外膜腐蚀mask\n",
    "\n",
    "        mask_out_list.append(out_mask)\n",
    "        mask_in_list.append(in_mask)\n",
    "        mask_both_list.append(both_mask)\n",
    "        mask_both_erode_list.append(both_mask_erode)\n",
    "\n",
    "        pred_narrow = 1 - (np.sum(in_mask) / np.sum(both_mask))\n",
    "        pred_erode_narrow = 1 - (np.sum(in_mask) / np.sum(both_mask_erode))\n",
    "\n",
    "        pn.append(pred_narrow)\n",
    "        pne.append(pred_erode_narrow)\n",
    "\n",
    "        if False:\n",
    "            print(\n",
    "                f'pred_narrow:{pred_narrow:.2f} | pred_narrow:{pred_erode_narrow:.2f}'\n",
    "            )\n",
    "\n",
    "    mask[\"out\"] = mask_out_list\n",
    "    mask[\"in\"] = mask_in_list\n",
    "    mask[\"both\"] = mask_both_list\n",
    "    mask[\"both_erode\"] = mask_both_erode_list\n",
    "\n",
    "    mask_transbts_all[file_name] = mask\n",
    "    pn_transbts_all[file_name] = pd.Series(pn)\n",
    "    pne_transbts_all[file_name] = pd.Series(pne)\n",
    "\n",
    "if True:\n",
    "    with pd.ExcelWriter(f'{model_name}.xlsx') as writer:\n",
    "        df_pn_all = pd.DataFrame(data=pn_transbts_all)\n",
    "        df_pn_all.to_excel(writer,\n",
    "                           sheet_name=\"diameter stenosis\",\n",
    "                           index=True,\n",
    "                           header=True,\n",
    "                           startrow=0,\n",
    "                           startcol=0)\n",
    "\n",
    "    with pd.ExcelWriter(f'{model_name}_erode.xlsx') as writer:\n",
    "        df_pne_all = pd.DataFrame(data=pne_transbts_all)\n",
    "        df_pne_all.to_excel(writer,\n",
    "                            sheet_name=\"diameter stenosis\",\n",
    "                            index=True,\n",
    "                            header=True,\n",
    "                            startrow=0,\n",
    "                            startcol=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算壁厚\n",
    "- 用1.5mm阈值来区分当前帧图像有无斑块，将有斑块帧的狭窄率绘制成图\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_isolate(inputs, threshold_area=0.5):\n",
    "    mask = np.zeros((inputs.shape[0], inputs.shape[1]), dtype=np.uint8)\n",
    "    mask[np.sum(inputs, axis=-1) > 0] = 1\n",
    "    mask = morphology.remove_small_objects(mask.astype(np.bool8),\n",
    "                                           np.sum(mask) * threshold_area,\n",
    "                                           connectivity=8).astype(np.uint8)\n",
    "    # outputs = np.expand_dims(mask, -1) * inputs\n",
    "    outputs = mask * inputs\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def minimum_external_circle(img):\n",
    "    contours, _ = cv2.findContours(img, cv2.RETR_TREE,\n",
    "                                   cv2.CHAIN_APPROX_NONE)  # 提取轮廓\n",
    "    img = np.expand_dims(img, -1).repeat(3, -1)\n",
    "\n",
    "    cnt = contours[0]\n",
    "    (x, y), radius = cv2.minEnclosingCircle(cnt)\n",
    "    center = (int(x), int(y))  # 最小内接圆圆心\n",
    "    radius = int(radius)  # 最小内接圆直径\n",
    "    cv2.circle(img, center, radius, (0, 255, 0), 2)\n",
    "    cv2.circle(img, center, 1, (0, 255, 0), 2)\n",
    "    return (x, y), radius, img\n",
    "\n",
    "\n",
    "# 把笛卡尔坐标转化为极坐标\n",
    "def to_polar(vector, x, y):\n",
    "    v_length = np.sqrt((vector[1] - int(x))**2 + (vector[0] - int(y))**2)\n",
    "    v_angle = np.arctan2(vector[0] - int(y), vector[1] - int(x))\n",
    "    return (v_length, np.around(v_angle, 2))\n",
    "\n",
    "\n",
    "def circle_max_distance(polar):\n",
    "    angle_range = np.linspace(-3.14, 3.14, int((3.14 * 2) / 0.01 + 1))\n",
    "    polar = np.array(polar)\n",
    "    polar_angle = polar[:, 1]\n",
    "    radial = []\n",
    "    for angle in angle_range:\n",
    "        idx_list = np.argwhere(polar_angle == np.around(angle, 2))\n",
    "        if len(idx_list) != 0:\n",
    "            distance = np.max(polar[idx_list][:, 0, 0]) - np.min(\n",
    "                polar[idx_list][:, 0, 0])\n",
    "            radial.append(int(distance))\n",
    "\n",
    "    return max(radial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_distance = {}\n",
    "for i, data_tuple in enumerate(list(mask_all.items())):\n",
    "    data = data_tuple[1][\"out\"]\n",
    "    name = data_tuple[0]\n",
    "    frame_distance = []\n",
    "    for j, frame in enumerate(data):\n",
    "        frame_pad = np.pad(frame, ((100, 100), (100, 100)), 'constant', constant_values=0)\n",
    "        frame_pad = cv2.morphologyEx(frame_pad, cv2.MORPH_CLOSE, kernel=np.ones((15, 15), np.uint8))\n",
    "        frame = frame_pad[100:-100, 100:-100]\n",
    "        frame = remove_isolate(frame)\n",
    "\n",
    "        area_pad = np.pad(data_tuple[1][\"both\"][j],\n",
    "                          ((100, 100), (100, 100)),\n",
    "                          'constant',\n",
    "                          constant_values=0)\n",
    "        area_pad = cv2.morphologyEx(area_pad,\n",
    "                                    cv2.MORPH_CLOSE,\n",
    "                                    kernel=np.ones((15, 15), np.uint8))\n",
    "        area = area_pad[100:-100, 100:-100]\n",
    "        area = remove_isolate(area)\n",
    "\n",
    "\n",
    "        (x, y), radius, visual_frame = minimum_external_circle(np.array(area, dtype=np.uint8))\n",
    "\n",
    "        frame_index = np.argwhere(frame == 1)\n",
    "\n",
    "        polar = []\n",
    "        for idx in range(len(frame_index)):\n",
    "            polar.append(to_polar(frame_index[idx], x, y))\n",
    "        polar = sorted(polar, key=lambda item: item[1])\n",
    "\n",
    "        frame_distance.append(circle_max_distance(polar))\n",
    "\n",
    "        # plot.figure(j)\n",
    "        # plot.imshow(visual_frame)\n",
    "        # plot.title(str(circle_max_distance(polar)))\n",
    "\n",
    "    data_distance[name] = frame_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rvm_distance = {}\n",
    "for i, data_tuple in enumerate(list(mask_rvm_all.items())):\n",
    "    data = data_tuple[1][\"out\"]\n",
    "    name = data_tuple[0]\n",
    "    frame_distance = []\n",
    "    for j, frame in enumerate(data):\n",
    "        frame_pad = np.pad(frame, ((100, 100), (100, 100)), 'constant', constant_values=0)\n",
    "        frame_pad = cv2.morphologyEx(frame_pad, cv2.MORPH_CLOSE, kernel=np.ones((15, 15), np.uint8))\n",
    "        frame = frame_pad[100:-100, 100:-100]\n",
    "        frame = remove_isolate(frame)\n",
    "\n",
    "        area_pad = np.pad(data_tuple[1][\"both\"][j],\n",
    "                          ((100, 100), (100, 100)),\n",
    "                          'constant',\n",
    "                          constant_values=0)\n",
    "        area_pad = cv2.morphologyEx(area_pad,\n",
    "                                    cv2.MORPH_CLOSE,\n",
    "                                    kernel=np.ones((15, 15), np.uint8))\n",
    "        area = area_pad[100:-100, 100:-100]\n",
    "        area = remove_isolate(area)\n",
    "\n",
    "\n",
    "        (x, y), radius, visual_frame = minimum_external_circle(np.array(area, dtype=np.uint8))\n",
    "\n",
    "        frame_index = np.argwhere(frame == 1)\n",
    "\n",
    "        polar = []\n",
    "        for idx in range(len(frame_index)):\n",
    "            polar.append(to_polar(frame_index[idx], x, y))\n",
    "        polar = sorted(polar, key=lambda item: item[1])\n",
    "\n",
    "        try:\n",
    "            frame_distance.append(circle_max_distance(polar))\n",
    "        except:\n",
    "            frame_distance.append(0)\n",
    "            print(name)\n",
    "\n",
    "        # plot.figure(j)\n",
    "        # plot.imshow(visual_frame)\n",
    "        # plot.title(str(circle_max_distance(polar)))\n",
    "\n",
    "    data_rvm_distance[name] = frame_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202203140858390011VAS.nii.gz\n"
     ]
    }
   ],
   "source": [
    "data_3dunet_distance = {}\n",
    "for i, data_tuple in enumerate(list(mask_3dunet_all.items())):\n",
    "    data = data_tuple[1][\"out\"]\n",
    "    name = data_tuple[0]\n",
    "    frame_distance = []\n",
    "    for j, frame in enumerate(data):\n",
    "        frame_pad = np.pad(frame, ((100, 100), (100, 100)), 'constant', constant_values=0)\n",
    "        frame_pad = cv2.morphologyEx(frame_pad, cv2.MORPH_CLOSE, kernel=np.ones((15, 15), np.uint8))\n",
    "        frame = frame_pad[100:-100, 100:-100]\n",
    "        frame = remove_isolate(frame)\n",
    "\n",
    "        area_pad = np.pad(data_tuple[1][\"both\"][j],\n",
    "                          ((100, 100), (100, 100)),\n",
    "                          'constant',\n",
    "                          constant_values=0)\n",
    "        area_pad = cv2.morphologyEx(area_pad,\n",
    "                                    cv2.MORPH_CLOSE,\n",
    "                                    kernel=np.ones((15, 15), np.uint8))\n",
    "        area = area_pad[100:-100, 100:-100]\n",
    "        area = remove_isolate(area)\n",
    "\n",
    "\n",
    "        (x, y), radius, visual_frame = minimum_external_circle(np.array(area, dtype=np.uint8))\n",
    "\n",
    "        frame_index = np.argwhere(frame == 1)\n",
    "\n",
    "        polar = []\n",
    "        for idx in range(len(frame_index)):\n",
    "            polar.append(to_polar(frame_index[idx], x, y))\n",
    "        polar = sorted(polar, key=lambda item: item[1])\n",
    "\n",
    "        try:\n",
    "            frame_distance.append(circle_max_distance(polar))\n",
    "        except:\n",
    "            frame_distance.append(0)\n",
    "            print(name)\n",
    "\n",
    "        # plot.figure(j)\n",
    "        # plot.imshow(visual_frame)\n",
    "        # plot.title(str(circle_max_distance(polar)))\n",
    "\n",
    "    data_3dunet_distance[name] = frame_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "print(len(data_3dunet_distance[\"202203140858390011VAS.nii.gz\"]))\n",
    "print(len(list(mask_3dunet_all[\"202203140858390011VAS.nii.gz\"]['out'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for image in list(mask_3dunet_all[\"202203140858390011VAS.nii.gz\"]['out']):\n",
    "    plot.imsave(f\"/Volumes/昊大侠/工作/实习相关/微创卜算子医疗科技有限公司/陈嘉懿组/数据/短轴动态狭窄率/result/狭窄率图表_0920/未命名文件夹/{i}.png\", image)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202203081456170036VAS.nii.gz\n",
      "202204020917510011VAS.nii.gz\n",
      "IM_0010.nii.gz\n",
      "IM_0010.nii.gz\n",
      "IM_0010.nii.gz\n",
      "IM_0010.nii.gz\n",
      "IM_0010.nii.gz\n",
      "IM_0010.nii.gz\n",
      "IM_0010.nii.gz\n",
      "IM_0010.nii.gz\n",
      "IM_0010.nii.gz\n",
      "IM_0010.nii.gz\n",
      "IM_0010.nii.gz\n"
     ]
    }
   ],
   "source": [
    "data_transbts_distance = {}\n",
    "for i, data_tuple in enumerate(list(mask_transbts_all.items())):\n",
    "    data = data_tuple[1][\"out\"]\n",
    "    name = data_tuple[0]\n",
    "    frame_distance = []\n",
    "    for j, frame in enumerate(data):\n",
    "        frame_pad = np.pad(frame, ((100, 100), (100, 100)), 'constant', constant_values=0)\n",
    "        frame_pad = cv2.morphologyEx(frame_pad, cv2.MORPH_CLOSE, kernel=np.ones((15, 15), np.uint8))\n",
    "        frame = frame_pad[100:-100, 100:-100]\n",
    "        frame = remove_isolate(frame)\n",
    "\n",
    "        area_pad = np.pad(data_tuple[1][\"both\"][j],\n",
    "                          ((100, 100), (100, 100)),\n",
    "                          'constant',\n",
    "                          constant_values=0)\n",
    "        area_pad = cv2.morphologyEx(area_pad,\n",
    "                                    cv2.MORPH_CLOSE,\n",
    "                                    kernel=np.ones((15, 15), np.uint8))\n",
    "        area = area_pad[100:-100, 100:-100]\n",
    "        area = remove_isolate(area)\n",
    "\n",
    "\n",
    "        (x, y), radius, visual_frame = minimum_external_circle(np.array(area, dtype=np.uint8))\n",
    "\n",
    "        frame_index = np.argwhere(frame == 1)\n",
    "\n",
    "        polar = []\n",
    "        for idx in range(len(frame_index)):\n",
    "            polar.append(to_polar(frame_index[idx], x, y))\n",
    "        polar = sorted(polar, key=lambda item: item[1])\n",
    "\n",
    "        try:\n",
    "            frame_distance.append(circle_max_distance(polar))\n",
    "        except:\n",
    "            frame_distance.append(0)\n",
    "            print(name)\n",
    "\n",
    "        # plot.figure(j)\n",
    "        # plot.imshow(visual_frame)\n",
    "        # plot.title(str(circle_max_distance(polar)))\n",
    "\n",
    "    data_transbts_distance[name] = frame_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "print(len(data_transbts_distance['202203081456170036VAS.nii.gz']))\n",
    "print(len(list(mask_transbts_all[\"202203081456170036VAS.nii.gz\"]['out'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for image in list(mask_transbts_all[\"202203081456170036VAS.nii.gz\"]['out']):\n",
    "    plot.imsave(\n",
    "        f\"/Volumes/昊大侠/工作/实习相关/微创卜算子医疗科技有限公司/陈嘉懿组/数据/短轴动态狭窄率/result/狭窄率图表_0920/未命名文件夹/{i}.png\",\n",
    "        image)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卡阈值选出斑块帧\n",
    "# 视频中外膜径向最大值(无斑块33,39,44,49,79)\n",
    "spacing_pixels = np.array(\n",
    "    pd.read_excel(\"/Users/WangHao/Desktop/TODO/Data/动态测试集spacing.xlsx\").values)\n",
    "\n",
    "for k, v in data_distance.items():\n",
    "    voxel = int(spacing_pixels[np.argwhere(spacing_pixels[:, 0] == k[:-7])][0][0][1]) / 5\n",
    "    for idx, data in enumerate(v):\n",
    "        if data / voxel <= 1.5:\n",
    "            pne_all[k][idx] = 0\n",
    "        else:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卡阈值选出斑块帧\n",
    "# 视频中外膜径向最大值(无斑块33,39,44,49,79)\n",
    "spacing_pixels = np.array(\n",
    "    pd.read_excel(\"/Users/WangHao/Desktop/TODO/Data/动态测试集spacing.xlsx\").values)\n",
    "\n",
    "for k, v in data_rvm_distance.items():\n",
    "    voxel = int(spacing_pixels[np.argwhere(\n",
    "        spacing_pixels[:, 0] == k[:-7])][0][0][1]) / 5\n",
    "    for idx, data in enumerate(v):\n",
    "        if data / voxel <= 1.5:\n",
    "            pne_rvm_all[k][idx] = 0\n",
    "        else:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卡阈值选出斑块帧\n",
    "# 视频中外膜径向最大值(无斑块33,39,44,49,79)\n",
    "spacing_pixels = np.array(\n",
    "    pd.read_excel(\"/Users/WangHao/Desktop/TODO/Data/动态测试集spacing.xlsx\").values)\n",
    "\n",
    "for k, v in data_3dunet_distance.items():\n",
    "    voxel = int(spacing_pixels[np.argwhere(\n",
    "        spacing_pixels[:, 0] == k[:-7])][0][0][1]) / 5\n",
    "    for idx, data in enumerate(v):\n",
    "        if data / voxel <= 1.5:\n",
    "            pne_3dunet_all[k][idx] = 0\n",
    "        else:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卡阈值选出斑块帧\n",
    "# 视频中外膜径向最大值(无斑块33,39,44,49,79)\n",
    "spacing_pixels = np.array(\n",
    "    pd.read_excel(\"/Users/WangHao/Desktop/TODO/Data/动态测试集spacing.xlsx\").values)\n",
    "\n",
    "for k, v in data_transbts_distance.items():\n",
    "    voxel = int(spacing_pixels[np.argwhere(\n",
    "        spacing_pixels[:, 0] == k[:-7])][0][0][1]) / 5\n",
    "    for idx, data in enumerate(v):\n",
    "        if data / voxel <= 1.5:\n",
    "            pn_transbts_all[k][idx] = 0\n",
    "        else:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = f\"/Volumes/昊大侠/工作/实习相关/微创卜算子医疗科技有限公司/陈嘉懿组/数据/短轴动态狭窄率/result/狭窄率图表_0920/figs_1.5mm\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "for idx in range(len(pne_all)):\n",
    "    assert sorted(list(pne_all.keys()))[idx] == sorted(\n",
    "            list(pn_transbts_all.keys()))[idx] == sorted(list(\n",
    "            pne_3dunet_all.keys()))[idx] == sorted(list(pne_rvm_all.keys()))[idx]\n",
    "\n",
    "    title = sorted(list(pne_all.keys()))[idx][:-7]\n",
    "\n",
    "    fig_x = list(pne_all[sorted(list(pne_all.keys()))[idx]].index)\n",
    "    fig_y = list(pne_all[sorted(list(pne_all.keys()))[idx]].values)\n",
    "\n",
    "    fig_x_1 = list(pne_3dunet_all[sorted(list(\n",
    "        pne_3dunet_all.keys()))[idx]].index)\n",
    "    fig_y_1 = list(pne_3dunet_all[sorted(list(\n",
    "        pne_3dunet_all.keys()))[idx]].values)\n",
    "\n",
    "    fig_x_2 = list(pn_transbts_all[sorted(list(\n",
    "        pn_transbts_all.keys()))[idx]].index)\n",
    "    fig_y_2 = list(pn_transbts_all[sorted(list(\n",
    "        pn_transbts_all.keys()))[idx]].values)\n",
    "\n",
    "    fig_x_3 = list(pne_rvm_all[sorted(list(pne_rvm_all.keys()))[idx]].index)\n",
    "    fig_y_3 = list(pne_rvm_all[sorted(list(pne_rvm_all.keys()))[idx]].values)\n",
    "\n",
    "    plot.rcParams.update({\"font.size\": 10})\n",
    "    fig = plot.figure(idx, figsize=(18, 6), dpi=300)\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.set(title=title,\n",
    "           xlabel='frame',\n",
    "           ylabel='diameter stenosis',\n",
    "           ylim=[0, 1])\n",
    "\n",
    "    ax.plot(fig_x, fig_y, 'm', label='label')\n",
    "\n",
    "    ax.plot(fig_x_1, fig_y_1, 'g', label='3dunet')\n",
    "\n",
    "    ax.plot(fig_x_2, fig_y_2, 'c', label='transbts')\n",
    "\n",
    "    ax.plot(fig_x_3, fig_y_3, 'b', label='rvm')\n",
    "\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    fig.savefig(f'{save_dir}/{title}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _take_channels(*xs, ignore_channels=None):\n",
    "    if ignore_channels is None:\n",
    "        return xs\n",
    "    else:\n",
    "        channels = [channel for channel in range(xs[0].shape[1]) if channel not in ignore_channels]\n",
    "        xs = [torch.index_select(x, dim=1, index=torch.tensor(channels).to(x.device)) for x in xs]\n",
    "        return xs\n",
    "\n",
    "\n",
    "def _threshold(x, threshold=None):\n",
    "    if threshold is not None:\n",
    "        return (x > threshold).type(x.dtype)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "class AccuracyProportion(nn.Module):\n",
    "    def __init__(self, proportion=0.5, threshold=None, ignore_channels=None, eps=1e-7):\n",
    "        super().__init__()\n",
    "        self.proportion = proportion\n",
    "        self.threshold = threshold\n",
    "        self.ignore_channels = ignore_channels\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, pr, gt):\n",
    "        assert pr.shape[0] == gt.shape[0]\n",
    "\n",
    "        pr = _threshold(pr, threshold=self.threshold)\n",
    "        pr, gt = _take_channels(pr, gt, ignore_channels=self.ignore_channels)\n",
    "\n",
    "        sum_nums = pr.shape[0]\n",
    "        nums = 0\n",
    "        for idx in range(sum_nums):\n",
    "            intersection = torch.sum(gt[idx] * pr[idx])\n",
    "            union = torch.sum(gt[idx]) + torch.sum(pr[idx]) - intersection + self.eps\n",
    "            score = (intersection + self.eps) / union\n",
    "\n",
    "            if score > self.proportion:\n",
    "                nums += 1\n",
    "        ap_score = nums / sum_nums\n",
    "\n",
    "        return ap_score\n",
    "\n",
    "\n",
    "class ExpectedAverageOverlap(nn.Module):\n",
    "    def __init__(self, threshold=None, ignore_channels=None, time_dim=0, eps=1e-7):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "        self.ignore_channels = ignore_channels\n",
    "        self.time_dim = time_dim\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, pr, gt):\n",
    "        assert pr.shape[self.time_dim] == gt.shape[self.time_dim]\n",
    "\n",
    "        pr = _threshold(pr, threshold=self.threshold)\n",
    "        pr, gt = _take_channels(pr, gt, ignore_channels=self.ignore_channels)\n",
    "\n",
    "        nums = pr.shape[self.time_dim]\n",
    "        score = 0\n",
    "        for idx in range(nums):\n",
    "            temp = 0\n",
    "            for k in range(idx):\n",
    "                tp = torch.sum((gt[k] == pr[k]).type(pr.dtype))\n",
    "                temp += tp / (gt[k].view(-1).shape[0] + self.eps)\n",
    "\n",
    "            score += temp / (idx+1)\n",
    "        eao_score = score / nums\n",
    "\n",
    "        return eao_score\n",
    "    \n",
    "\n",
    "class DistanceMetric(nn.Module):\n",
    "        def __init__(self, method_name=\"hd\", voxelspacing=None, threshold=None, ignore_channels=None):\n",
    "            super().__init__()\n",
    "            self.method_name = method_name\n",
    "            self.voxelspacing = voxelspacing\n",
    "            self.threshold = threshold\n",
    "            self.ignore_channels = ignore_channels\n",
    "    \n",
    "        def forward(self, pr, gt):\n",
    "            assert len(pr.shape) == len(gt.shape) == 2, \"输入数据应该是一个背景纯黑的面\"\n",
    "\n",
    "            pr = _threshold(pr, threshold=self.threshold)\n",
    "            pr, gt = _take_channels(pr, gt, ignore_channels=self.ignore_channels)\n",
    "\n",
    "            pr = pr.cpu().numpy()\n",
    "            gt = gt.cpu().numpy()\n",
    "\n",
    "            if self.method_name == \"asd\":\n",
    "                distance_score = medmetric.binary.asd(pr, gt, voxelspacing=self.voxelspacing)\n",
    "            elif self.method_name == \"assd\":\n",
    "                distance_score = medmetric.binary.assd(pr, gt, voxelspacing=self.voxelspacing)\n",
    "            elif self.method_name == \"hd\":\n",
    "                distance_score = medmetric.binary.hd(pr, gt, voxelspacing=self.voxelspacing)\n",
    "            elif self.method_name == \"hd95\":    \n",
    "                distance_score = medmetric.binary.hd95(pr, gt, voxelspacing=self.voxelspacing)\n",
    "            else:\n",
    "                print(f\"方法{self.method_name}不存在，请设置方法为asd、assd、hd或hd95\")\n",
    "                sys.exit()\n",
    "            \n",
    "            return distance_score\n",
    "\n",
    "\n",
    "def metric_functions(loss_name):\n",
    "    if loss_name == 'dice':\n",
    "        return smp.utils.metrics.Fscore(beta=1, threshold=0.5)\n",
    "    elif loss_name == 'ac':\n",
    "        return smp.utils.metrics.Accuracy(threshold=0.5)\n",
    "    elif loss_name == 'pre':\n",
    "        return smp.utils.metrics.Precision(threshold=0.5)\n",
    "    elif loss_name == 'r':\n",
    "        return smp.utils.metrics.Recall(threshold=0.5)\n",
    "    elif loss_name == 'f1':\n",
    "        return smp.utils.metrics.Fscore(beta=1, threshold=0.5)\n",
    "    elif loss_name == 'iou':\n",
    "        return smp.utils.metrics.IoU(threshold=0.5)\n",
    "    elif loss_name == 'ap@0.5':\n",
    "        return AccuracyProportion(proportion=0.5, threshold=0.5)\n",
    "    elif loss_name == 'ap@0.7':\n",
    "        return AccuracyProportion(proportion=0.7, threshold=0.5)\n",
    "    elif loss_name == 'eao':\n",
    "        return ExpectedAverageOverlap(threshold=0.5)\n",
    "    elif loss_name == 'asd':\n",
    "        return DistanceMetric(method_name=\"asd\", threshold=0.5)\n",
    "    elif loss_name == 'assd':\n",
    "        return DistanceMetric(method_name=\"assd\", threshold=0.5)\n",
    "    elif loss_name == 'hd':\n",
    "        return DistanceMetric(method_name=\"hd\", threshold=0.5)\n",
    "    elif loss_name == 'hd95':\n",
    "        return DistanceMetric(method_name=\"hd95\", threshold=0.5)\n",
    "    else:\n",
    "        print('The loss function name: {} is invalid'.format(loss_name))\n",
    "        sys.exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['out', 'in', 'both', 'both_erode'])\n",
      "02220820210305_XJ_20210305082931543.nii.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jb/g3ylc11574sd3g6w3t57g5rm0000gn/T/ipykernel_18799/2628242762.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1662188943573/work/torch/csrc/utils/tensor_new.cpp:233.)\n",
      "  a = torch.tensor(list(mask_transbts_all.items())[0][1]['both'])\n"
     ]
    }
   ],
   "source": [
    "print(list(mask_transbts_all.items())[0][1].keys())\n",
    "print(list(mask_transbts_all.items())[0][0])\n",
    "a = torch.tensor(list(mask_transbts_all.items())[0][1]['both'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dice_in': '0.91±0.07', 'dice_bothunique': '0.92±0.06', 'ac_in': '0.00±0.00', 'ac_bothunique': '0.00±0.00', 'pre_in': '0.89±0.10', 'pre_bothunique': '0.91±0.09', 'r_in': '0.94±0.04', 'r_bothunique': '0.94±0.03', 'f1_in': '0.91±0.07', 'f1_bothunique': '0.92±0.06', 'iou_in': '0.83±0.10', 'iou_bothunique': '0.86±0.09', 'ap@0.5_in': '0.97±0.09', 'ap@0.5_bothunique': '0.98±0.09', 'ap@0.7_in': '0.89±0.16', 'ap@0.7_bothunique': '0.94±0.14', 'eao_in': '0.91±0.04', 'eao_bothunique': '0.90±0.05', 'asd_in': '0.84±1.10', 'asd_bothunique': '0.79±1.04', 'assd_in': '0.01±0.01', 'assd_bothunique': '0.50±0.53', 'hd_in': '2.86±3.26', 'hd_bothunique': '2.82±3.16', 'hd95_in': '2.29±2.87', 'hd95_bothunique': '2.17±2.76'}\n"
     ]
    }
   ],
   "source": [
    "def count_index(mask_data, mask_label, spacing_pixels, model_name, save_dir):\n",
    "\n",
    "    dice_in_list = []\n",
    "    dice_bothunique_list = []\n",
    "\n",
    "    ac_in_list = []\n",
    "    ac_bothunique_list = []\n",
    "\n",
    "    pre_in_list = []\n",
    "    pre_bothunique_list = []\n",
    "\n",
    "    r_in_list = []\n",
    "    r_bothunique_list = []\n",
    "\n",
    "    f1_in_list = []\n",
    "    f1_bothunique_list = []\n",
    "\n",
    "    iou_in_list = []\n",
    "    iou_bothunique_list = []\n",
    "\n",
    "    ap_05_in_list = []\n",
    "    ap_05_bothunique_list = []\n",
    "\n",
    "    ap_07_in_list = []\n",
    "    ap_07_bothunique_list = []\n",
    "\n",
    "    eao_in_list = []\n",
    "    eao_bothunique_list = []\n",
    "\n",
    "    asd_in_list = []\n",
    "    asd_bothunique_list = []\n",
    "\n",
    "    assd_in_list = []\n",
    "    assd_bothunique_list = []\n",
    "\n",
    "    hd_in_list = []\n",
    "    hd_bothunique_list = []\n",
    "\n",
    "    hd95_in_list = []\n",
    "    hd95_bothunique_list = []\n",
    "\n",
    "\n",
    "    for i, file_name in enumerate(list(mask_data.keys())):\n",
    "\n",
    "        data_in = mask_data[file_name][\"in\"]\n",
    "        label_in = mask_label[file_name][\"in\"]\n",
    "        data_both = mask_data[file_name][\"both\"]\n",
    "        label_both = mask_label[file_name][\"both\"]\n",
    "\n",
    "        data_in = torch.tensor(data_in)\n",
    "        label_in = torch.tensor(label_in)\n",
    "        data_both = torch.tensor(data_both)\n",
    "        label_both = torch.tensor(label_both)\n",
    "\n",
    "        if False:\n",
    "            label_in = cv2.resize(np.array(label_in).transpose((1, 2, 0)), (128, 128),\n",
    "                       interpolation=cv2.INTER_NEAREST).transpose((2, 0, 1))\n",
    "            label_in = torch.tensor(label_in).contiguous()\n",
    "            label_both = cv2.resize(np.array(label_both).transpose((1, 2, 0)), (128, 128),\n",
    "                       interpolation=cv2.INTER_NEAREST).transpose((2, 0, 1))\n",
    "            label_both = torch.tensor(label_both).contiguous()\n",
    "\n",
    "        voxel = 5 / int(spacing_pixels[np.argwhere(\n",
    "            spacing_pixels[:, 0] == file_name[:-7])][0][0][1])\n",
    "\n",
    "        if True:\n",
    "            # 计算指标\n",
    "            dice_in_all = metric_functions(\"dice\")(data_in, label_in)\n",
    "            dice_in_list.append(dice_in_all.cpu())\n",
    "            dice_bothunique = metric_functions(\"dice\")(data_both, label_both)\n",
    "            dice_bothunique_list.append(dice_bothunique.cpu())\n",
    "\n",
    "            ac_in = metric_functions(\"ac\")(data_in, label_in)\n",
    "            ac_in_list.append(ac_in.cpu())\n",
    "            ac_bothunique = metric_functions(\"ac\")(data_both, label_both)\n",
    "            ac_bothunique_list.append(ac_bothunique.cpu())\n",
    "\n",
    "            pre_in = metric_functions(\"pre\")(data_in, label_in)\n",
    "            pre_in_list.append(pre_in.cpu())\n",
    "            pre_bothunique = metric_functions(\"pre\")(data_both, label_both)\n",
    "            pre_bothunique_list.append(pre_bothunique.cpu())\n",
    "\n",
    "            r_in = metric_functions(\"r\")(data_in, label_in)\n",
    "            r_in_list.append(r_in.cpu())\n",
    "            r_bothunique = metric_functions(\"r\")(data_both, label_both)\n",
    "            r_bothunique_list.append(r_bothunique.cpu())\n",
    "\n",
    "            f1_in = metric_functions(\"f1\")(data_in, label_in)\n",
    "            f1_in_list.append(f1_in.cpu())\n",
    "            f1_bothunique = metric_functions(\"f1\")(data_both, label_both)\n",
    "            f1_bothunique_list.append(f1_bothunique.cpu())\n",
    "\n",
    "            iou_in = metric_functions(\"iou\")(data_in, label_in)\n",
    "            iou_in_list.append(iou_in.cpu())\n",
    "            iou_bothunique = metric_functions(\"iou\")(data_both, label_both)\n",
    "            iou_bothunique_list.append(iou_bothunique.cpu())\n",
    "\n",
    "            ap_05_in = metric_functions(\"ap@0.5\")(data_in, label_in)\n",
    "            ap_05_in_list.append(ap_05_in)\n",
    "            ap_05_bothunique = metric_functions(\"ap@0.5\")(data_both, label_both)\n",
    "            ap_05_bothunique_list.append(ap_05_bothunique)\n",
    "\n",
    "            ap_07_in = metric_functions(\"ap@0.7\")(data_in, label_in)\n",
    "            ap_07_in_list.append(ap_07_in)\n",
    "            ap_07_bothunique = metric_functions(\"ap@0.7\")(data_both, label_both)\n",
    "            ap_07_bothunique_list.append(ap_07_bothunique)\n",
    "\n",
    "            eao_in = metric_functions(\"eao\")(data_in, label_in)\n",
    "            eao_in_list.append(eao_in.cpu())\n",
    "            eao_bothunique = metric_functions(\"eao\")(data_both, label_both)\n",
    "            eao_bothunique_list.append(eao_bothunique.cpu())\n",
    "\n",
    "            asd_in = asd_bothunique = assd_in = assd_bothunique = hd_in = hd_bothunique = hd95_in = hd95_bothunique = 0\n",
    "            for j in range(data_in.shape[0]):\n",
    "                asd_in += DistanceMetric(method_name=\"asd\",\n",
    "                                         voxelspacing=voxel,\n",
    "                                         threshold=0.5)(data_in[j],\n",
    "                                                        label_in[j])\n",
    "                asd_bothunique += DistanceMetric(method_name=\"asd\",\n",
    "                                                 voxelspacing=voxel,\n",
    "                                                 threshold=0.5)(data_both[j],\n",
    "                                                                label_both[j])\n",
    "                assd_in = DistanceMetric(method_name=\"assd\",\n",
    "                                         voxelspacing=voxel,\n",
    "                                         threshold=0.5)(data_in[j],\n",
    "                                                        label_in[j])\n",
    "                assd_bothunique += DistanceMetric(method_name=\"assd\",\n",
    "                                                  voxelspacing=voxel,\n",
    "                                                  threshold=0.5)(data_both[j],\n",
    "                                                                 label_both[j])\n",
    "                hd_in += DistanceMetric(method_name=\"hd\",\n",
    "                                        voxelspacing=voxel,\n",
    "                                        threshold=0.5)(data_in[j], label_in[j])\n",
    "                hd_bothunique += DistanceMetric(method_name=\"hd\",\n",
    "                                                voxelspacing=voxel,\n",
    "                                                threshold=0.5)(data_both[j],\n",
    "                                                               label_both[j])\n",
    "                hd95_in += DistanceMetric(method_name=\"hd95\",\n",
    "                                          voxelspacing=voxel,\n",
    "                                          threshold=0.5)(data_in[j],\n",
    "                                                         label_in[j])\n",
    "                hd95_bothunique += DistanceMetric(method_name=\"hd95\",\n",
    "                                                  voxelspacing=voxel,\n",
    "                                                  threshold=0.5)(data_both[j],\n",
    "                                                                 label_both[j])\n",
    "\n",
    "            asd_in_list.append(asd_in / data_in.shape[0])\n",
    "            asd_bothunique_list.append(asd_bothunique / data_in.shape[0])\n",
    "            assd_in_list.append(assd_in / data_in.shape[0])\n",
    "            assd_bothunique_list.append(assd_bothunique / data_in.shape[0])\n",
    "            hd_in_list.append(hd_in / data_in.shape[0])\n",
    "            hd_bothunique_list.append(hd_bothunique / data_in.shape[0])\n",
    "            hd95_in_list.append(hd95_in / data_in.shape[0])\n",
    "            hd95_bothunique_list.append(hd95_bothunique / data_in.shape[0])\n",
    "\n",
    "\n",
    "    if True:\n",
    "        test_loss_dict = dict({\n",
    "            \"dice_in\":\n",
    "            f'{np.array(dice_in_list).mean(axis=0):.2f}±{np.array(dice_in_list).std(axis=0):.2f}',\n",
    "            \"dice_bothunique\":\n",
    "            f'{np.array(dice_bothunique_list).mean(axis=0):.2f}±{np.array(dice_bothunique_list).std(axis=0):.2f}',\n",
    "            \"ac_in\":\n",
    "            f'{np.array(ac_in_list).mean(axis=0):.2f}±{np.array(ac_in_list).std(axis=0):.2f}',\n",
    "            \"ac_bothunique\":\n",
    "            f'{np.array(ac_bothunique_list).mean(axis=0):.2f}±{np.array(ac_bothunique_list).std(axis=0):.2f}',\n",
    "            \"pre_in\":\n",
    "            f'{np.array(pre_in_list).mean(axis=0):.2f}±{np.array(pre_in_list).std(axis=0):.2f}',\n",
    "            \"pre_bothunique\":\n",
    "            f'{np.array(pre_bothunique_list).mean(axis=0):.2f}±{np.array(pre_bothunique_list).std(axis=0):.2f}',\n",
    "            \"r_in\":\n",
    "            f'{np.array(r_in_list).mean(axis=0):.2f}±{np.array(r_in_list).std(axis=0):.2f}',\n",
    "            \"r_bothunique\":\n",
    "            f'{np.array(r_bothunique_list).mean(axis=0):.2f}±{np.array(r_bothunique_list).std(axis=0):.2f}',\n",
    "            \"f1_in\":\n",
    "            f'{np.array(f1_in_list).mean(axis=0):.2f}±{np.array(f1_in_list).std(axis=0):.2f}',\n",
    "            \"f1_bothunique\":\n",
    "            f'{np.array(f1_bothunique_list).mean(axis=0):.2f}±{np.array(f1_bothunique_list).std(axis=0):.2f}',\n",
    "            \"iou_in\":\n",
    "            f'{np.array(iou_in_list).mean(axis=0):.2f}±{np.array(iou_in_list).std(axis=0):.2f}',\n",
    "            \"iou_bothunique\":\n",
    "            f'{np.array(iou_bothunique_list).mean(axis=0):.2f}±{np.array(iou_bothunique_list).std(axis=0):.2f}',\n",
    "            \"ap@0.5_in\":\n",
    "            f'{np.array(ap_05_in_list).mean(axis=0):.2f}±{np.array(ap_05_in_list).std(axis=0):.2f}',\n",
    "            \"ap@0.5_bothunique\":\n",
    "            f'{np.array(ap_05_bothunique_list).mean(axis=0):.2f}±{np.array(ap_05_bothunique_list).std(axis=0):.2f}',\n",
    "            \"ap@0.7_in\":\n",
    "            f'{np.array(ap_07_in_list).mean(axis=0):.2f}±{np.array(ap_07_in_list).std(axis=0):.2f}',\n",
    "            \"ap@0.7_bothunique\":\n",
    "            f'{np.array(ap_07_bothunique_list).mean(axis=0):.2f}±{np.array(ap_07_bothunique_list).std(axis=0):.2f}',\n",
    "            \"eao_in\":\n",
    "            f'{np.array(eao_in_list).mean(axis=0):.2f}±{np.array(eao_in_list).std(axis=0):.2f}',\n",
    "            \"eao_bothunique\":\n",
    "            f'{np.array(eao_bothunique_list).mean(axis=0):.2f}±{np.array(eao_bothunique_list).std(axis=0):.2f}',\n",
    "            \"asd_in\":\n",
    "            f'{np.array(asd_in_list).mean(axis=0):.2f}±{np.array(asd_in_list).std(axis=0):.2f}',\n",
    "            \"asd_bothunique\":\n",
    "            f'{np.array(asd_bothunique_list).mean(axis=0):.2f}±{np.array(asd_bothunique_list).std(axis=0):.2f}',\n",
    "            \"assd_in\":\n",
    "            f'{np.array(assd_in_list).mean(axis=0):.2f}±{np.array(assd_in_list).std(axis=0):.2f}',\n",
    "            \"assd_bothunique\":\n",
    "            f'{np.array(assd_bothunique_list).mean(axis=0):.2f}±{np.array(assd_bothunique_list).std(axis=0):.2f}',\n",
    "            \"hd_in\":\n",
    "            f'{np.array(hd_in_list).mean(axis=0):.2f}±{np.array(hd_in_list).std(axis=0):.2f}',\n",
    "            \"hd_bothunique\":\n",
    "            f'{np.array(hd_bothunique_list).mean(axis=0):.2f}±{np.array(hd_bothunique_list).std(axis=0):.2f}',\n",
    "            \"hd95_in\":\n",
    "            f'{np.array(hd95_in_list).mean(axis=0):.2f}±{np.array(hd95_in_list).std(axis=0):.2f}',\n",
    "            \"hd95_bothunique\":\n",
    "            f'{np.array(hd95_bothunique_list).mean(axis=0):.2f}±{np.array(hd95_bothunique_list).std(axis=0):.2f}',\n",
    "        })\n",
    "\n",
    "\n",
    "        if True:\n",
    "            values = np.stack([\n",
    "            dice_in_list,\n",
    "            dice_bothunique_list,\n",
    "            ac_in_list,\n",
    "            ac_bothunique_list,\n",
    "            pre_in_list,\n",
    "            pre_bothunique_list,\n",
    "            r_in_list,\n",
    "            r_bothunique_list,\n",
    "            f1_in_list,\n",
    "            f1_bothunique_list,\n",
    "            iou_in_list,\n",
    "            iou_bothunique_list,\n",
    "            ap_05_in_list,\n",
    "            ap_05_bothunique_list,\n",
    "            ap_07_in_list,\n",
    "            ap_07_bothunique_list,\n",
    "            eao_in_list,\n",
    "            eao_bothunique_list,\n",
    "            asd_in_list,\n",
    "            asd_bothunique_list,\n",
    "            assd_in_list,\n",
    "            assd_bothunique_list,\n",
    "            hd_in_list,\n",
    "            hd_bothunique_list,\n",
    "            hd95_in_list,\n",
    "            hd95_bothunique_list\n",
    "            ])\n",
    "            index = [\n",
    "                \"dice内膜\",\n",
    "                \"dice外膜\",\n",
    "                \"ac内膜\",\n",
    "                \"ac外膜\",\n",
    "                \"pre内膜\",\n",
    "                \"pre外膜\",\n",
    "                \"r内膜\",\n",
    "                \"r外膜\",\n",
    "                \"f1内膜\",\n",
    "                \"f1外膜\",\n",
    "                \"iou内膜\",\n",
    "                \"iou外膜\",\n",
    "                \"ap_05内膜\",\n",
    "                \"ap_05外膜\",\n",
    "                \"ap_07内膜\",\n",
    "                \"ap_07外膜\",\n",
    "                \"eao内膜\",\n",
    "                \"eao外膜\",\n",
    "                \"asd内膜\",\n",
    "                \"asd外膜\",\n",
    "                \"assd内膜\",\n",
    "                \"assd外膜\",\n",
    "                \"hd内膜\",\n",
    "                \"hd外膜\",\n",
    "                \"hd95内膜\",\n",
    "                \"hd95外膜\",\n",
    "            ]\n",
    "            columns = list(mask_data.keys())\n",
    "            df = pd.DataFrame(values, index=index, columns=columns)\n",
    "            with pd.ExcelWriter(f'{save_dir}/{model_name}_detail.xlsx') as writer:\n",
    "                df.to_excel(writer,\n",
    "                            sheet_name='Sheet1',\n",
    "                            index=True,\n",
    "                            header=True,\n",
    "                            startrow=0,\n",
    "                            startcol=0)\n",
    "\n",
    "\n",
    "        if False:\n",
    "            df = pd.DataFrame(test_loss_dict, index=[\"均值±标准差\"])\n",
    "            with pd.ExcelWriter(f'{save_dir}/{model_name}.xlsx') as writer:\n",
    "                df.to_excel(writer,\n",
    "                            sheet_name='Sheet1',\n",
    "                            index=True,\n",
    "                            header=True,\n",
    "                            startrow=0,\n",
    "                            startcol=0)\n",
    "\n",
    "        print(test_loss_dict)\n",
    "\n",
    "\n",
    "model_name = \"3dunet\"\n",
    "save_dir = \"/Volumes/昊大侠/工作/实习相关/微创卜算子医疗科技有限公司/陈嘉懿组/数据/短轴动态狭窄率/result/狭窄率图表_0920/count_index\"\n",
    "\n",
    "spacing_pixels = np.array(\n",
    "    pd.read_excel(\"/Users/WangHao/Desktop/TODO/Data/动态测试集spacing.xlsx\").values)\n",
    "\n",
    "count_index(mask_3dunet_all, mask_all, spacing_pixels, model_name, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(mask_3dunet_all['_20210128075939_0818310.nii.gz']['in'])\n",
    "b = torch.tensor(mask_rvm_all['_20210128075939_0818310.nii.gz']['in'])\n",
    "c = cv2.resize(np.array(a).transpose((1, 2, 0)), (128, 128),\n",
    "               interpolation=cv2.INTER_NEAREST).transpose((2, 0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4]\n",
    "b = [3, 4, 5, 6]\n",
    "values = np.stack([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>11</th>\n",
       "      <th>22</th>\n",
       "      <th>33</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nei</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wai</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     11  22  33  44\n",
       "nei   1   2   3   4\n",
       "wai   3   4   5   6"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(values, index=[\"nei\", \"wai\"], columns=[\"11\", \"22\", \"33\", \"44\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['内膜', '外膜', '内膜', '外膜', '内膜', '外膜']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = [\"内膜\", \"外膜\"] * 3\n",
    "index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7567524e79b96d316162151a38259d28be4bc298929f85b9103bf7fbca02c0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
