{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 按格式删除文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# 读取路径\n",
    "import torch\n",
    "\n",
    "image_sequence_path = \"/Users/WangHao/工作/实习相关/微创卜算子医疗科技有限公司/陈嘉懿组/数据/佳文数据_0722/短轴视频_0722\"\n",
    "image_sequence_list = os.listdir(image_sequence_path)\n",
    "image_sequence_list = sorted(image_sequence_list)\n",
    "\n",
    "for path_name in image_sequence_list:\n",
    "    # 读取文件\n",
    "    ext = \"npy\"\n",
    "    file_list = glob(f\"{os.path.join(image_sequence_path, path_name)}/*.{ext}\")\n",
    "    try:\n",
    "        for file in file_list:\n",
    "            os.remove(file)\n",
    "    except:\n",
    "        print(f\"{path_name}中不存在{ext}类型文件\")\n",
    "\n",
    "print(\"运行结束\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 修改像道数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "filePath = '/Volumes/昊大侠/工作/实习相关/微创卜算子医疗科技有限公司/陈嘉懿组/数据/短轴动态狭窄率/dataset_0802/label/06570820220302_CA MASHAOYONG_20220302091109144'\n",
    "if not os.path.exists(filePath.replace('dataset_0706', 'dataset_0706_nb')):\n",
    "    os.mkdir(filePath.replace('dataset_0706', 'dataset_0706_nb'))\n",
    "\n",
    "for root, dirs, files in os.walk(filePath):\n",
    "    for i in files:\n",
    "        if 'label' in i:\n",
    "            label = cv2.imdecode(np.fromfile(f\"{root}/{i}\", dtype=np.uint8), -1)\n",
    "            label[..., 0] = 0\n",
    "            image = cv2.imread(root + '/' + i.replace('label', 'image'))\n",
    "\n",
    "            if not os.path.exists(\n",
    "                    root.replace('dataset_0706', 'dataset_0706_nb')):\n",
    "                os.mkdir(root.replace('dataset_0706', 'dataset_0706_nb'))\n",
    "\n",
    "            cv2.imencode('.png', label)[-1].tofile(\n",
    "                root.replace('dataset_0706', 'dataset_0706_nb') + '/' + i)\n",
    "            cv2.imencode('.png', image)[-1].tofile(\n",
    "                root.replace('dataset_0706', 'dataset_0706_nb') + '/' +\n",
    "                i.replace('label', 'image'))\n",
    "\n",
    "print(\"运行结束\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 去除小连通"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import morphology\n",
    "\n",
    "def remove_isolate(inputs, threshold_area=0.5):\n",
    "    \"\"\"\n",
    "    inputs: x*y*3\n",
    "    \"\"\"\n",
    "    mask = np.zeros((inputs.shape[0], inputs.shape[1]), dtype=np.uint8)\n",
    "    mask[np.sum(inputs, axis=-1) > 0] = 1\n",
    "    mask = morphology.remove_small_objects(mask.astype(np.bool8),\n",
    "                                           np.sum(mask) * threshold_area,\n",
    "                                           connectivity=8).astype(np.uint8)\n",
    "    outputs = np.expand_dims(mask, -1) * inputs\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "filePath = '/Volumes/昊大侠/工作/实习相关/微创卜算子医疗科技有限公司/陈嘉懿组/数据/短轴动态狭窄率/dataset/label'\n",
    "\n",
    "for root, dirs, files in os.walk(filePath):\n",
    "    for file_name in files:\n",
    "        ext = \".png\"\n",
    "        if ext in file_name and \"._\" not in file_name:\n",
    "            label = cv2.imdecode(np.fromfile(f\"{root}/{file_name}\", dtype=np.uint8), -1)\n",
    "            label = remove_isolate(label)\n",
    "            cv2.imencode('.png', label)[-1].tofile(f\"{root}/{file_name}\")\n",
    "\n",
    "print(\"运行结束\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 生成重叠图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "path = r\"/Users/WangHao/Downloads/ToData\"\n",
    "save_path = \"\"\n",
    "\n",
    "# 通过DFS实现统一逻辑处理同一层次的文件对象\n",
    "for root, dirs, files in os.walk(path):\n",
    "    if not dirs:\n",
    "        keywords = [\"label\", \"label_roi\"]\n",
    "        dir_name = root.split(\"/\")[-1]\n",
    "        keys = [key for key in keywords if key == dir_name]\n",
    "\n",
    "        if keys == [\"label\"]:\n",
    "            save_visual_path = root.replace(\"label\", \"visual\")\n",
    "            if not os.path.exists(save_visual_path):\n",
    "                os.makedirs(save_visual_path)\n",
    "            ext = \".png\"\n",
    "            for file_name in files:\n",
    "                if ext in file_name and \"._\" not in file_name:\n",
    "                    label = cv2.imread(os.path.join(root, file_name))\n",
    "                    image = cv2.imread(os.path.join(root, file_name).replace(\"label\", \"image\"))\n",
    "                    visual = cv2.addWeighted(image, 0.8, label, 0.2, 0)\n",
    "                    cv2.imwrite(os.path.join(save_visual_path, file_name), visual)\n",
    "\n",
    "        if keys == [\"label_roi\"]:\n",
    "            save_visual_roi_path = root.replace(\"label_roi\", \"visual_roi\")\n",
    "            if not os.path.exists(save_visual_roi_path):\n",
    "                os.makedirs(save_visual_roi_path)\n",
    "            ext = \".png\"\n",
    "            for file_name in files:\n",
    "                if ext in file_name and \"._\" not in file_name:\n",
    "                    label_roi = cv2.imread(os.path.join(root, file_name))\n",
    "                    image_roi = cv2.imread(os.path.join(root, file_name).replace(\"label_roi\", \"image_roi\"))\n",
    "                    visual_roi = cv2.addWeighted(image_roi, 0.8, label_roi, 0.2, 0)\n",
    "                    cv2.imwrite(os.path.join(save_visual_roi_path, file_name), visual_roi)\n",
    "\n",
    "print(\"运行结束\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 文件拷贝移动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "path = r\"/Volumes/昊大侠/工作/实习相关/微创卜算子医疗科技有限公司/陈嘉懿组/数据/短轴动态狭窄率/动态返修3\"\n",
    "save_path = \"/Volumes/昊大侠/工作/实习相关/微创卜算子医疗科技有限公司/陈嘉懿组/数据/短轴动态狭窄率/动态返修3\"\n",
    "\n",
    "# 通过DFS实现统一逻辑处理同一层次的文件对象\n",
    "for root, dirs, files in os.walk(path):\n",
    "    if not dirs:\n",
    "        keywords = [\"visual\", \"label\", \"roi\"]\n",
    "        dir_name = root.split(\"/\")[-1]\n",
    "        keys = [key for key in keywords if key in dir_name]\n",
    "        if not keys:\n",
    "            save_image_path = os.path.join(save_path, \"image\", root.split(\"/\")[-2])\n",
    "            if not os.path.exists(save_image_path):\n",
    "                os.makedirs(save_image_path)\n",
    "            ext = \".png\"\n",
    "            for file_name in files:\n",
    "                if ext in file_name:\n",
    "                    shutil.copy(os.path.join(root, file_name), save_image_path)\n",
    "\n",
    "        if keys == [\"label\"]:\n",
    "            save_label_path = os.path.join(save_path, \"label\", root.split(\"/\")[-2])\n",
    "            if not os.path.exists(save_label_path):\n",
    "                os.makedirs(save_label_path)\n",
    "            ext = \".png\"\n",
    "            for file_name in files:\n",
    "                if ext in file_name:\n",
    "                    shutil.copy(os.path.join(root, file_name), save_label_path)\n",
    "\n",
    "print(\"运行结束\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 文件夹拷贝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运行结束\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "path_roi_label = \"/Volumes/昊大侠/工作/实习相关/微创卜算子医疗科技有限公司/陈嘉懿组/数据/短轴动态狭窄率/dataset/dataset_roi/label\"\n",
    "path_roi_image = \"/Volumes/昊大侠/工作/实习相关/微创卜算子医疗科技有限公司/陈嘉懿组/数据/短轴动态狭窄率/dataset/dataset_roi/image\"\n",
    "path_label = \"/Volumes/昊大侠/工作/实习相关/微创卜算子医疗科技有限公司/陈嘉懿组/数据/短轴动态狭窄率/dataset/label\"\n",
    "path_image = \"/Volumes/昊大侠/工作/实习相关/微创卜算子医疗科技有限公司/陈嘉懿组/数据/短轴动态狭窄率/dataset/image\"\n",
    "\n",
    "save_dir = \"/Volumes/昊大侠/工作/实习相关/微创卜算子医疗科技有限公司/陈嘉懿组/数据/短轴动态狭窄率/dataset_usable_0815\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "keys_list = os.listdir(path_roi_label)\n",
    "\n",
    "for dirs in os.listdir(path_label):\n",
    "    if dirs not in keys_list:\n",
    "        save_path = os.path.join(save_dir, dirs)\n",
    "        # shutil.copytree(os.path.join(path_roi_label, dirs), os.path.join(save_path, \"label_roi\"))\n",
    "        # shutil.copytree(os.path.join(path_roi_image, dirs).replace(\"label\", \"image\"), os.path.join(save_path, \"image_roi\"))\n",
    "        shutil.copytree(os.path.join(path_label, dirs), os.path.join(save_path, \"label\"))\n",
    "        shutil.copytree(os.path.join(path_image, dirs).replace(\"label\", \"image\"), os.path.join(save_path, \"image\"))\n",
    "\n",
    "print(\"运行结束\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## *Get ROI data pair*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from skimage import morphology\n",
    "\n",
    "\n",
    "def file_remove(file_list):\n",
    "    try:\n",
    "        file_list.remove('.DS_Store')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    try:\n",
    "        file_list.remove('._.DS_Store')\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "\n",
    "def remove_isolate(inputs, threshold_area=0.5):\n",
    "    \"\"\"\n",
    "    inputs: x*y*3\n",
    "    \"\"\"\n",
    "    mask = np.zeros((inputs.shape[0], inputs.shape[1]), dtype=np.uint8)\n",
    "    mask[np.sum(inputs, axis=-1) > 0] = 1\n",
    "    mask = morphology.remove_small_objects(mask.astype(np.bool8),\n",
    "                                           np.sum(mask) * threshold_area,\n",
    "                                           connectivity=8).astype(np.uint8)\n",
    "    outputs = np.expand_dims(mask, -1) * inputs\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def crop_array(image, label, up, down, left, right):\n",
    "    \"\"\"\n",
    "    image:x*y*3 uint8\n",
    "    label:x*y*3 uint8\n",
    "    \"\"\"\n",
    "\n",
    "    crop_image = image[up:down, left:right, :]\n",
    "    crop_label = label[up:down, left:right, :]\n",
    "\n",
    "    return crop_image, crop_label\n",
    "\n",
    "\n",
    "def count_list_place(base_path, files):\n",
    "    place = []\n",
    "    file_dir = f\"{base_path}/{files}\"\n",
    "    path_4 = os.listdir(file_dir)\n",
    "    file_remove(path_4)\n",
    "    for file_name in path_4:\n",
    "        if \"._\" not in file_name:\n",
    "            data = cv2.imdecode(\n",
    "                np.fromfile(f\"{file_dir}/{file_name}\", dtype=np.uint8), -1)\n",
    "\n",
    "            data = remove_isolate(data)\n",
    "            data_gray = cv2.cvtColor(data, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "            y_sum = np.sum(data_gray, axis=1)\n",
    "            x_sum = np.sum(data_gray, axis=0)\n",
    "\n",
    "            up = min(np.where(y_sum != 0)[0]) - 20 if min(np.where(y_sum != 0)[0]) > 20 else 0\n",
    "            down = max(np.where(y_sum != 0)[0]) + 20 if max(np.where(y_sum != 0)[0]) < data.shape[0] - 20 else data.shape[0]\n",
    "            left = min(np.where(x_sum != 0)[0]) - 20 if min(np.where(x_sum != 0)[0]) > 20 else 0\n",
    "            right = max(np.where(x_sum != 0)[0]) + 20 if min(np.where(x_sum != 0)[0]) < data.shape[1] - 20 else data.shape[1]\n",
    "\n",
    "        place.append([up, down, left, right])\n",
    "\n",
    "    place = np.array(place)\n",
    "    place_min = np.min(place, axis=0)\n",
    "    place_max = np.max(place, axis=0)\n",
    "    up, down, left, right = place_min[0], place_max[1], place_min[2], place_max[3]\n",
    "    assert (down < data.shape[0]) and (right < data.shape[1])\n",
    "\n",
    "    return up, down, left, right\n",
    "\n",
    "\n",
    "def count_place(data, path):\n",
    "    data_gray = cv2.cvtColor(data, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    y_sum = np.sum(data_gray, axis=1)\n",
    "    x_sum = np.sum(data_gray, axis=0)\n",
    "    try:\n",
    "        up = min(np.where(y_sum != 0)[0]) - 20 if min(np.where(y_sum != 0)[0]) > 20 else 0\n",
    "        down = max(np.where(y_sum != 0)[0]) + 20 if max(np.where(y_sum != 0)[0]) < data.shape[0] - 20 else data.shape[0]\n",
    "        left = min(np.where(x_sum != 0)[0]) - 20 if min(np.where(x_sum != 0)[0]) > 20 else 0\n",
    "        right = max(np.where(x_sum != 0)[0]) + 20 if min(np.where(x_sum != 0)[0]) < data.shape[1] - 20 else data.shape[1]\n",
    "        flag = 0\n",
    "    except ValueError:\n",
    "        flag = 1\n",
    "        print(path)\n",
    "\n",
    "    return up, down, left, right, flag\n",
    "\n",
    "\n",
    "file_path = r\"/Volumes/昊大侠/工作/实习相关/微创卜算子医疗科技有限公司/陈嘉懿组/数据/短轴动态狭窄率/dataset/0816/3\"\n",
    "save_base = r\"/Volumes/昊大侠/工作/实习相关/微创卜算子医疗科技有限公司/陈嘉懿组/数据/短轴动态狭窄率/dataset/0816\"\n",
    "if not os.path.exists(save_base):\n",
    "    os.mkdir(save_base)\n",
    "save_base_label = f\"{save_base}/label\"\n",
    "if not os.path.exists(save_base_label):\n",
    "    os.mkdir(save_base_label)\n",
    "save_base_image =  f\"{save_base}/image\"\n",
    "if not os.path.exists(save_base_image):\n",
    "    os.mkdir(save_base_image)\n",
    "\n",
    "for root, dirs, files in os.walk(file_path):\n",
    "    if not dirs:\n",
    "        keywords = [\"label\"]\n",
    "        dir_name = root.split(\"/\")[-2]\n",
    "        keys = [key for key in keywords if key in dir_name]\n",
    "        if keys:\n",
    "            print(f\"process {root}\")\n",
    "            ext = \".png\"\n",
    "            for file_name in files:\n",
    "                if ext in file_name and \"._\" not in file_name:\n",
    "                    file_path_label = os.path.join(root, file_name)\n",
    "                    label = cv2.imdecode(np.fromfile(file_path_label, dtype=np.uint8), -1)\n",
    "                    label = remove_isolate(label)\n",
    "                    file_path_image = file_path_label.replace(\"label\", \"image\")\n",
    "                    image = cv2.imdecode(np.fromfile(file_path_image, dtype=np.uint8), -1)\n",
    "\n",
    "                    up, down, left, right, flag = count_place(label, file_path_label)\n",
    "                    if flag:\n",
    "                        break\n",
    "\n",
    "                    crop_image, crop_label = crop_array(image, label, up, down, left, right)\n",
    "                    save_path_label = os.path.join(save_base_label, root.split(\"/\")[-1])\n",
    "                    if not os.path.exists(save_path_label):\n",
    "                        os.mkdir(save_path_label)\n",
    "                    save_path_image = os.path.join(save_base_image, root.split(\"/\")[-1])\n",
    "                    if not os.path.exists(save_path_image):\n",
    "                        os.mkdir(save_path_image)\n",
    "\n",
    "                    cv2.imencode('.png', crop_label)[1].tofile(\n",
    "                        os.path.join(save_path_label, file_name))\n",
    "                    cv2.imencode('.png', crop_image)[1].tofile(\n",
    "                        os.path.join(save_path_image, file_name))\n",
    "\n",
    "print(\"运行结束\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 寻找重复名称文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = list(open(\"/Volumes/昊大侠/工作/实习相关/微创卜算子医疗科技有限公司/陈嘉懿组/数据/短轴动态狭窄率/王昊数据_0801/已返修/数据名单.txt\", \"r\"))\n",
    "\n",
    "data_dict = {}\n",
    "for path_1 in data_dir:\n",
    "    path_list = []\n",
    "    data_1 = path_1.split(\"/\")[-1]\n",
    "    for path_2 in data_dir:\n",
    "        data_2 = path_2.split(\"/\")[-1]\n",
    "        if data_1 == data_2:\n",
    "            path_list.append(path_2)\n",
    "\n",
    "    data_dict[data_1] = path_list\n",
    "\n",
    "print(data_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7567524e79b96d316162151a38259d28be4bc298929f85b9103bf7fbca02c0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
